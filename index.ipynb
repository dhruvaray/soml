{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "\n",
    "Popular question and answer (qna) site -  stackoverflow (+ their sister sites) allows for download of monthly data dumps from https://archive.org/details/stackexchange.\n",
    "\n",
    "With this data, can we classify the questions/answers based on\n",
    "\n",
    "* Conceptual v/s howto question \n",
    "* Beginner v/s intermediate v/s hard/trick\n",
    "* A particular question is associated with another question in terms of the next things to do or perhaps the pre-requisites?\n",
    "* Predict the next question a user may ask based on this current search\n",
    "\n",
    "The taxanomy could be a useful layout of the land for a student of the area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema\n",
    "\n",
    "The schema for their data is located @ https://ia800500.us.archive.org/22/items/stackexchange/readme.txt.\n",
    "    \n",
    "Unfortunately, the data is dumped in an XML format and there is preliminary effort to convert that data into CSV format. We have written a converter (convert2csv.py) for the tables of interest.\n",
    "\n",
    "The schemas for the tables of interest are shown below.\n",
    "\n",
    "\n",
    "## Posts\n",
    "-----------\n",
    "- Id\n",
    "- PostTypeId\n",
    "  - 1: Question\n",
    "  - 2: Answer\n",
    "- ParentID (only present if PostTypeId is 2)\n",
    "- AcceptedAnswerId (only present if PostTypeId is 1)\n",
    "- CreationDate\n",
    "- Score\n",
    "- ViewCount\n",
    "- Body\n",
    "- OwnerUserId\n",
    "- LastEditorUserId\n",
    "- LastEditorDisplayName=\"Jeff Atwood\"\n",
    "- LastEditDate=\"2009-03-05T22:28:34.823\"\n",
    "- LastActivityDate=\"2009-03-11T12:51:01.480\"\n",
    "- CommunityOwnedDate=\"2009-03-11T12:51:01.480\"\n",
    "- ClosedDate=\"2009-03-11T12:51:01.480\"\n",
    "- Title=\n",
    "- Tags=\n",
    "- AnswerCount\n",
    "- CommentCount\n",
    "- FavoriteCount\n",
    "\n",
    "## Comments\n",
    "---------------------------\n",
    "- Id\n",
    "- PostId\n",
    "- Score\n",
    "- Text, e.g.: \"@Stu Thompson: Seems possible to me - why not try it?\"\n",
    "- CreationDate, e.g.:\"2008-09-06T08:07:10.730\"\n",
    "- UserId\n",
    "\n",
    "## Post History\n",
    "---------------------------\n",
    "- Id\n",
    "- PostHistoryTypeId\n",
    "    - 1: Initial Title - The first title a question is asked with.\n",
    "    - 2: Initial Body - The first raw body text a post is submitted with.\n",
    "    - 3: Initial Tags - The first tags a question is asked with.\n",
    "    - 4: Edit Title - A question's title has been changed.\n",
    "    - 5: Edit Body - A post's body has been changed, the raw text is stored here as markdown.\n",
    "    - 6: Edit Tags - A question's tags have been changed.\n",
    "    - 7: Rollback Title - A question's title has reverted to a previous version.\n",
    "    - 8: Rollback Body - A post's body has reverted to a previous version - the raw text is stored here.\n",
    "    - 9: Rollback Tags - A question's tags have reverted to a previous version.\n",
    "    - 10: Post Closed - A post was voted to be closed.\n",
    "    - 11: Post Reopened - A post was voted to be reopened.\n",
    "    - 12: Post Deleted - A post was voted to be removed.\n",
    "    - 13: Post Undeleted - A post was voted to be restored.\n",
    "    - 14: Post Locked - A post was locked by a moderator.\n",
    "    - 15: Post Unlocked - A post was unlocked by a moderator.\n",
    "    - 16: Community Owned - A post has become community owned.\n",
    "    - 17: Post Migrated - A post was migrated.\n",
    "    - 18: Question Merged - A question has had another, deleted question merged into itself.\n",
    "    - 19: Question Protected - A question was protected by a moderator\n",
    "    - 20: Question Unprotected - A question was unprotected by a moderator\n",
    "    - 21: Post Disassociated - An admin removes the OwnerUserId from a post.\n",
    "    - 22: Question Unmerged - A previously merged question has had its answers and votes restored.\n",
    "- PostId\n",
    "- RevisionGUID: At times more than one type of history record can be recorded by a single action.  \n",
    "- CreationDate: \"2009-03-05T22:28:34.823\"\n",
    "- UserId\n",
    "- UserDisplayName: populated if a user has been removed and no longer referenced by user Id\n",
    "- Comment: This field will contain the comment made by the user who edited a post\n",
    "- Text: A raw version of the new value for a given revision. \n",
    "- CloseReasonId\n",
    "    - 1: Exact Duplicate - This question covers exactly the same ground as earlier questions on this topic; its answers may be merged with another identical question.\n",
    "    - 2: off-topic\n",
    "    - 3: subjective\n",
    "    - 4: not a real question\n",
    "    - 7: too localized\n",
    "       \n",
    "       \n",
    "## Users\n",
    "---------------------------\n",
    " - Id\n",
    " - Reputation\n",
    " - CreationDate\n",
    " - DisplayName\n",
    " - EmailHash\n",
    " - LastAccessDate\n",
    " - WebsiteUrl\n",
    " - Location\n",
    " - Age\n",
    " - AboutMe\n",
    " - Views\n",
    " - UpVotes\n",
    " - DownVotes\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion from XML to CSV\n",
    "\n",
    "Run python convert2csv.py to convert each of the xml files to their CSV equivalents. For columns/attributes which contain textual data, the converter encodes them with base64 encoding so that handling of quotes and special characters (separators) is avoided. \n",
    "\n",
    "When the data is read back into the dataframe, the corresponding decode (from base64) needs to happen. The converter also creates a sample file of 100 rows for each xml data dump converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import base64\n",
    "import math\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import word2vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "\n",
    "SAMPLE_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When should I use can? When should I use could...</td>\n",
       "      <td>When do I use \"can\" or \"could\"?</td>\n",
       "      <td>&lt;word-choice&gt;&lt;tenses&gt;&lt;politeness&gt;&lt;subjunctive-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doesn't \"quint\" mean \"five\"?  What does that h...</td>\n",
       "      <td>Where does the \"quint\" in \"quintessential\" com...</td>\n",
       "      <td>&lt;etymology&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which is the correct use of these two words, a...</td>\n",
       "      <td>When should I use \"shall\" versus \"will\"?</td>\n",
       "      <td>&lt;future-tense&gt;&lt;shall-future&gt;&lt;will-future&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I think most folk happily use either \"while\" o...</td>\n",
       "      <td>When did \"while\" and \"whilst\" become interchan...</td>\n",
       "      <td>&lt;word-choice&gt;&lt;grammar&gt;&lt;etymology&gt;&lt;conjunctions&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nI may not be coming in tomorrow... \\nI mig...</td>\n",
       "      <td>\"May\" &amp; \"Might\": What's the right context?</td>\n",
       "      <td>&lt;word-choice&gt;&lt;grammar&gt;&lt;modal-verbs&gt;&lt;auxiliary-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body  \\\n",
       "0  When should I use can? When should I use could...   \n",
       "1  Doesn't \"quint\" mean \"five\"?  What does that h...   \n",
       "2  Which is the correct use of these two words, a...   \n",
       "4  I think most folk happily use either \"while\" o...   \n",
       "5  \\n\\nI may not be coming in tomorrow... \\nI mig...   \n",
       "\n",
       "                                               Title  \\\n",
       "0                    When do I use \"can\" or \"could\"?   \n",
       "1  Where does the \"quint\" in \"quintessential\" com...   \n",
       "2           When should I use \"shall\" versus \"will\"?   \n",
       "4  When did \"while\" and \"whilst\" become interchan...   \n",
       "5         \"May\" & \"Might\": What's the right context?   \n",
       "\n",
       "                                                Tags  \n",
       "0  <word-choice><tenses><politeness><subjunctive-...  \n",
       "1                                        <etymology>  \n",
       "2          <future-tense><shall-future><will-future>  \n",
       "4    <word-choice><grammar><etymology><conjunctions>  \n",
       "5  <word-choice><grammar><modal-verbs><auxiliary-...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = pd.read_csv('posts.csv',nrows=SAMPLE_SIZE).dropna(subset=['Body','Title'])\n",
    "posts['Body'] = posts['Body'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "posts['Title'] = posts['Title'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "posts[['Body','Title', 'Tags']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that we have stripped out the html formatting tags with BeautifulSoup before reassigning back to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>I think you need to edit the title of your que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>It's correct when you're accessing a method of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yes, I would think in almost any context where...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Would you say `It can certainly be \"acceptable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@serg555: Would you expect anything less on a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                               Text\n",
       "0      9  I think you need to edit the title of your que...\n",
       "1     12  It's correct when you're accessing a method of...\n",
       "2      2  Yes, I would think in almost any context where...\n",
       "3      0  Would you say `It can certainly be \"acceptable...\n",
       "4      4  @serg555: Would you expect anything less on a ..."
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.read_csv('comments.csv',nrows=SAMPLE_SIZE).dropna()\n",
    "comments['Text'] = comments['Text'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "comments[['Score','Text']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#posthistory = pd.read_csv('posthistory.csv',nrows=SAMPLE_SIZE).dropna(subset=['Text'])\n",
    "#posthistory['Text'] = posthistory['Text'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "#posthistory[['Text']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>AboutMe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on the server farm</td>\n",
       "      <td>Hi, I'm not really a person.\\nI'm a background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corvallis, OR</td>\n",
       "      <td>Developer on the Stack Overflow team.  Find me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Developer on the Stack Overflow team.\\nWas dub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>I design stuff for Stack Exchange. Also a prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>I slip my front end into the back end, and the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Location                                            AboutMe\n",
       "0  on the server farm  Hi, I'm not really a person.\\nI'm a background...\n",
       "1       Corvallis, OR  Developer on the Stack Overflow team.  Find me...\n",
       "2        New York, NY  Developer on the Stack Overflow team.\\nWas dub...\n",
       "3         Raleigh, NC  I design stuff for Stack Exchange. Also a prof...\n",
       "4          California  I slip my front end into the back end, and the..."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('users.csv',nrows=SAMPLE_SIZE).dropna(subset=['AboutMe','Location'])\n",
    "users['AboutMe'] = users['AboutMe'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "users['Location'] = users['Location'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "users[['Location','AboutMe']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further cleansing\n",
    "\n",
    "* Remove (html) tags & carriage returns from the Text field\n",
    "* Remove stop words (pick up the nltk stop words)\n",
    "* Use PorterStemmer to stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#global\n",
    "p_stemmer = PorterStemmer()\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('use')\n",
    "#print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SentenceTokens():\n",
    "    def __init__(self,df,field):\n",
    "        self.field = field\n",
    "        self.df = df\n",
    "    \n",
    "    def __iter__(self):\n",
    "      for index, row in self.df.iterrows():\n",
    "         raw_sentence = row[self.field].replace('\\n','').lower()\n",
    "         raw_tokens = filter(None, re.split(\"[ ?.,\\\"\\')()_-]+\",raw_sentence))\n",
    "         #stem_tokens = [p_stemmer.stem(tok) for tok in raw_tokens]\n",
    "         yield [tok for tok in raw_tokens if not tok in stop_words]\n",
    "\n",
    "#all posts is a list of (list of tokens). The inner list of tokens is created once for each post\n",
    "allposts = SentenceTokens(posts,'Title')\n",
    "\n",
    "#for p in allposts:\n",
    "#    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How frequently each term occurs within each document? We construct a document-term matrix.\n",
    "dictionary = corpora.Dictionary(allposts)\n",
    "#print(dictionary.token2id) #maps ids to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1)]\n"
     ]
    }
   ],
   "source": [
    "#bag of words\n",
    "corpus = [dictionary.doc2bow(text) for text in allposts]\n",
    "#corpus, is a list of vectors equal to the number of documents. \n",
    "#In each document vector is a series of tuples. \n",
    "print(corpus[0])\n",
    "#(term ID, term frequency) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, id2word = dictionary, passes=30)\n",
    "\n",
    "#num_topics: required. An LDA model requires the user to determine how many topics should be generated. \n",
    "#id2word: required. The LdaModel class requires our previous dictionary to map ids to strings.\n",
    "#passes: optional. The number of laps the model will take through corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  u'0.023*way + 0.012*especially + 0.012*better + 0.012*wrong + 0.012*context + 0.012*nouns'),\n",
       " (8,\n",
       "  u'0.055*vs + 0.019*word + 0.019*g + 0.019*line + 0.019*people + 0.019*standing'),\n",
       " (9,\n",
       "  u'0.029*come + 0.020*word + 0.020*words + 0.020*phrase + 0.020*employee + 0.020*always'),\n",
       " (5,\n",
       "  u'0.064*english + 0.028*used + 0.028*said + 0.019*write + 0.019*work + 0.019*email'),\n",
       " (2,\n",
       "  u'0.082*sentence + 0.036*instead + 0.036*e + 0.024*correct + 0.024*versus + 0.024*ending')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(num_topics=5, num_words=6)\n",
    "def understand(num_topics, num_words):\n",
    "    return ldamodel.print_topics(num_topics, num_words)\n",
    "    \n",
    "#Each generated topic is separated by a comma.\n",
    "#Within each topic are the three most probable words to appear in that topic.\n",
    "\n",
    "#interact(understand, x=widgets.IntSlider(min=0,max=300,step=1,value=10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el163221404346454025765648584978\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el163221404346454025765648584978_data = {\"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [9, 6, 10, 4, 8, 2, 3, 5, 7, 1], \"token.table\": {\"Topic\": [6, 5, 6, 4, 10, 5, 3, 9, 4, 7, 10, 1, 6, 1, 6, 6, 3, 8, 2, 4, 4, 3, 4, 5, 10, 4, 3, 10, 2, 2, 7, 9, 7, 8, 1, 5, 2, 5, 6, 4, 8, 2, 6, 10, 4, 2, 4, 2, 6, 10, 8, 10, 4, 5, 3, 2, 8, 1, 4, 6, 5, 1, 2, 10, 5, 5, 1, 3, 7, 5, 6, 4, 6, 4, 2, 4, 10, 4, 6, 1, 2, 7, 4, 1, 3, 4, 5, 6, 7, 10, 1, 4, 8, 3, 9, 9, 5, 8, 8, 2, 8, 2, 2, 9, 3, 6, 2, 1, 6, 2, 4, 5, 6, 8, 4, 6, 5, 10, 3, 1, 1, 7, 8, 10, 2, 3, 8, 8, 1, 3, 7, 9, 1, 7, 2, 6, 10, 1, 5, 6, 10, 10, 4, 7, 8, 9, 8, 3, 5, 10, 5, 8, 9, 7, 4, 3, 9, 5, 8, 1, 9, 5, 7, 1, 7, 3, 7, 9, 2, 3, 7, 3, 5, 4, 2, 8, 8, 3, 4, 5, 8, 9, 3, 8, 3, 3, 1, 8, 4, 5, 8, 7, 3, 7, 1, 4, 7, 8, 1, 10, 1, 5, 4, 4, 3, 10, 5, 6, 4, 8, 8, 10, 4, 1, 3, 1, 3, 5, 3, 3, 5, 9, 3, 6, 4, 8, 2, 5, 9, 6, 5, 7, 5, 6, 2, 7, 9, 5, 2, 2, 4, 6, 4, 5, 10, 3, 3, 9, 9, 9, 8, 6, 1, 4, 3, 1, 5, 1, 1, 6, 6, 7, 1, 1, 2, 2, 3, 4, 1, 6, 5, 8, 6, 1, 4, 7, 9, 4, 9, 8, 6, 7, 4, 7, 5, 6, 3, 7, 5, 4, 2, 4, 5, 7, 9, 4, 7, 7, 6, 8, 3, 7, 8, 9, 9, 2, 3, 4, 2, 2, 9, 1, 3, 10, 10, 1, 8, 10, 2, 6, 6, 3, 7, 3, 3, 3, 2, 2, 1, 3, 2, 9, 2, 7, 9, 2, 6, 5, 9, 6, 8, 1, 7, 8, 4, 9, 1, 4, 2, 9, 2, 5, 6, 1, 10, 10, 3, 2, 6, 9, 1, 6, 7, 5, 9, 4, 8, 10, 1, 6, 5, 1, 6, 6, 2, 6, 3, 8, 1, 9, 10, 1, 5, 8, 1, 2, 1, 10, 6, 3, 1, 5, 4, 5, 2, 4, 8, 9, 3, 1, 7, 8, 5, 7, 8, 1, 6, 1, 2, 4, 6, 8, 4, 6, 10, 2, 4, 9, 3, 9, 1, 2, 3, 5, 8, 1, 3, 4, 8, 2, 2, 4, 2, 4, 6, 1, 5, 8, 4, 6, 5, 6, 4, 5, 10, 10, 3, 3], \"Freq\": [0.83807820789072984, 0.56043988485051455, 0.56043988485051455, 0.5795681236165946, 0.5795681236165946, 0.84371012451275695, 0.56503114045154046, 0.56503114045154046, 0.29181508834787218, 0.29181508834787218, 0.29181508834787218, 0.53088446934229849, 0.83807820792443144, 0.80717299170989421, 0.83807820792789312, 0.83807820791538146, 0.8218914033136786, 0.85543988441866436, 0.81177624843626606, 0.83490951162670246, 0.83490951160764137, 0.54369192261271959, 0.83490951161586702, 0.58379523360532692, 0.58379523360532692, 0.8349095116499734, 0.82189140333541844, 0.89140604678464186, 0.81177624843838392, 0.3418876780916616, 0.3418876780916616, 0.3418876780916616, 0.84674685401425476, 0.855439884423565, 0.80717299176484691, 0.84371012451531979, 0.81177624844314433, 0.84371012451542238, 0.83807820789496479, 0.83490951163433891, 0.85543988443721797, 0.54616821422014938, 0.54616821422014938, 0.89140604670291967, 0.83490951160890547, 0.81177624842099316, 0.83490951163710758, 0.811776248432451, 0.83807820791410448, 0.89140604676011437, 0.57344584440455193, 0.89140604661137623, 0.83490951160822513, 0.84371012451127647, 0.82189140333588018, 0.55348894527972237, 0.55348894527972237, 0.53088446933721767, 0.55654309217512488, 0.55654309217512488, 0.84371012451682492, 0.80717299165073331, 0.81177624836449036, 0.89140604674514279, 0.84371012450721539, 0.8437101245031845, 0.27074884783616548, 0.54149769567233097, 0.27074884783616548, 0.56043990418564726, 0.56043990418564726, 0.55654309606126195, 0.55654309606126195, 0.55514395387516058, 0.81177624838793017, 0.57956810833727557, 0.57956810833727557, 0.5565430987059109, 0.5565430987059109, 0.80717299173333257, 0.54983650908860848, 0.54983650908860848, 0.83490951162394966, 0.18668424760804458, 0.18668424760804458, 0.18668424760804458, 0.18668424760804458, 0.18668424760804458, 0.18668424760804458, 0.18668424760804458, 0.41367677479315379, 0.41367677479315379, 0.41367677479315379, 0.56503104550228322, 0.56503104550228322, 0.87165486278793292, 0.84371012451448335, 0.8554398843958847, 0.85543988441976149, 0.81177624837569184, 0.85543988445628594, 0.81177624843550678, 0.81177624841700102, 0.87165486394722913, 0.82189140331999666, 0.83807820789996668, 0.81177624844177709, 0.80717299164510514, 0.83807820789334486, 0.18552651344809598, 0.18552651344809598, 0.55657954034428792, 0.18552651344809598, 0.85543988445050245, 0.55514395389800186, 0.83807820789618515, 0.84371012451882188, 0.89140604613950292, 0.8218914033678496, 0.80717299165491663, 0.27440753442551385, 0.54881506885102771, 0.85543988441344887, 0.89140604679498225, 0.53487420292353482, 0.41422754107319976, 0.41422754107319976, 0.85543988445760677, 0.33317487329078921, 0.33317487329078921, 0.33317487329078921, 0.33317487329078921, 0.41449007058588966, 0.41449007058588966, 0.74485590647295563, 0.14897118129459111, 0.14897118129459111, 0.80717299177171642, 0.56043987348577329, 0.56043987348577329, 0.89140604674393631, 0.89140604626124764, 0.56035265681245361, 0.56035265681245361, 0.85543988442674479, 0.87165486397954395, 0.85543988448142516, 0.8218914033204705, 0.84371012450308192, 0.89140604604631335, 0.84371012451400995, 0.85543988441147079, 0.87165486397524627, 0.84674685401357941, 0.83490951168364047, 0.82189140329014421, 0.8716548639242403, 0.5681508725183686, 0.5681508725183686, 0.80717299164870204, 0.87165486399087144, 0.84371012451947847, 0.84674685402402616, 0.40477544309482355, 0.40477544309482355, 0.55445851461427687, 0.55445851461427687, 0.87165486363485112, 0.40961901592725058, 0.40961901592725058, 0.40961901592725058, 0.82189140332866439, 0.84371012451509375, 0.83490951160484084, 0.55348894526114167, 0.55348894526114167, 0.85543988451365505, 0.54935824288305302, 0.54935824288305302, 0.84371012450729488, 0.5734458444270778, 0.87165486397137193, 0.82189140330887889, 0.85543988450571173, 0.82189140332094668, 0.8218914032960124, 0.80717299170453871, 0.85543988433582874, 0.55902109923838239, 0.55902109923838239, 0.85543988441152274, 0.84674685400856275, 0.55445849696112426, 0.55445849696112426, 0.23935397242673739, 0.23935397242673739, 0.47870794485347479, 0.23935397242673739, 0.80717299177938828, 0.89140604664215239, 0.80717299177723056, 0.84371012451201788, 0.83490951163128124, 0.83490951160258264, 0.82189140337075595, 0.89140604602596019, 0.84371012450624994, 0.83807820789235155, 0.83490951164150262, 0.8554398845098552, 0.58938720605506967, 0.58938720605506967, 0.83490951166403593, 0.53721188339895898, 0.53721188339895898, 0.39900721008761642, 0.39900721008761642, 0.84371012451442651, 0.82189140334588384, 0.8218914033188498, 0.84371012451056882, 0.58811368017687615, 0.82189140336499478, 0.83807820789364251, 0.56414655647025003, 0.56414655647025003, 0.42086108456766863, 0.42086108456766863, 0.42086108456766863, 0.8380782078960719, 0.84371012451229954, 0.84674685402688366, 0.67418935189337414, 0.33709467594668707, 0.81177624841586193, 0.57666836002562472, 0.57666836002562472, 0.8437101245018811, 0.81177624839703189, 0.81177624841056473, 0.55654309869786367, 0.55654309869786367, 0.8349095116084958, 0.84371012452017047, 0.89140604666116441, 0.5436919227274043, 0.56503113803138039, 0.56503113803138039, 0.87165486398717451, 0.87165486397990588, 0.85543988447334562, 0.83807820788899379, 0.80717299164954148, 0.83490951163503668, 0.82189140335528477, 0.80717299167480261, 0.84371012451028493, 0.80717299167260559, 0.40278394901152914, 0.40278394901152914, 0.83807820792069398, 0.84674685402342997, 0.80717299180194202, 0.80717299178042168, 0.81177624842847529, 0.32461116517221733, 0.32461116517221733, 0.32461116517221733, 0.80717299178140844, 0.83807820793102583, 0.42531424347302166, 0.42531424347302166, 0.8380782079161081, 0.54274323536478863, 0.54274323536478863, 0.84674685399334804, 0.87165486391028901, 0.83490951162791172, 0.87165486385259727, 0.85543988445366947, 0.83807820791042886, 0.846746854019787, 0.83490951163370974, 0.84674685400918681, 0.56043988485966167, 0.56043988485966167, 0.82189140332080768, 0.84674685402157834, 0.84371012451080318, 0.83490951160473892, 0.81177624844042751, 0.34143624616085944, 0.34143624616085944, 0.34143624616085944, 0.34143624616085944, 0.83490951166877192, 0.84674685402697725, 0.84674685402692973, 0.83807820792063403, 0.85543988444628594, 0.42044786165964904, 0.42044786165964904, 0.42044786165964904, 0.87165486396083425, 0.87165486397668979, 0.8117762483966684, 0.82189140336053401, 0.83490951161930871, 0.81177624842629015, 0.81177624837289541, 0.87165486357212396, 0.80717299171441625, 0.82189140334007682, 0.89140604658365075, 0.89140604614437002, 0.8071729917005882, 0.8554398844129637, 0.89140604657497258, 0.81177624843732732, 0.83807820790265586, 0.83807820791126741, 0.55445844173955039, 0.55445844173955039, 0.82189140332570088, 0.82189140337723421, 0.82189140330482147, 0.79766112035217029, 0.81177624843261154, 0.53721187639443169, 0.53721187639443169, 0.56023190755270535, 0.56023190755270535, 0.16969387225131574, 0.67877548900526297, 0.16969387225131574, 0.54616812078332078, 0.54616812078332078, 0.84371012451000282, 0.87165486391189995, 0.83807820788736553, 0.85543988436236484, 0.41656228218319241, 0.41656228218319241, 0.41656228218319241, 0.83490951169611327, 0.87165486396489711, 0.8071729918308419, 0.83490951161984095, 0.81177624843380769, 0.87165486394569747, 0.81177624841400531, 0.84371012451171379, 0.83807820793055532, 0.56606554355108785, 0.56606554355108785, 0.89140604660113754, 0.8218914033153859, 0.81177624839845819, 0.83807820790672249, 0.87165486396750413, 0.53088446929403921, 0.4224892921304918, 0.4224892921304918, 0.57525828049212591, 0.57525828049212591, 0.83490951162044957, 0.85543988446364905, 0.89140604662041278, 0.80717299185603786, 0.83807820790251453, 0.84371012451193639, 0.80717299179988644, 0.83807820790229948, 0.83807820788740151, 0.81177624843404284, 0.83807820788781862, 0.42258027224015637, 0.42258027224015637, 0.55803603944651026, 0.55803603944651026, 0.89140604671688706, 0.80717299177725932, 0.56295281783234519, 0.85543988451337427, 0.80717299179603075, 0.81177624837334683, 0.80717299169687318, 0.89140604613430918, 0.8380782078882888, 0.82189140336820332, 0.54644859590779071, 0.54644859590779071, 0.41798307584445166, 0.41798307584445166, 0.41301021410984801, 0.206505107054924, 0.206505107054924, 0.206505107054924, 0.82189140330881738, 0.80717299173731005, 0.84674685401284477, 0.85543988445263563, 0.42391691227283973, 0.42391691227283973, 0.85543988446109898, 0.80717299169991419, 0.83807820789011089, 0.49828161943902788, 0.12457040485975697, 0.12457040485975697, 0.12457040485975697, 0.24914080971951394, 0.41738361369687255, 0.41738361369687255, 0.89140604677531043, 0.41865983379999633, 0.41865983379999633, 0.41865983379999633, 0.82189140330214339, 0.8716548639429248, 0.20273748614099488, 0.20273748614099488, 0.20273748614099488, 0.20273748614099488, 0.20273748614099488, 0.2730382977124689, 0.2730382977124689, 0.2730382977124689, 0.2730382977124689, 0.53487420291646548, 0.54482061701496476, 0.54482061701496476, 0.40433468081985835, 0.40433468081985835, 0.83807820788839449, 0.41582582747163782, 0.41582582747163782, 0.41582582747163782, 0.556543097129514, 0.556543097129514, 0.5604398838525021, 0.5604398838525021, 0.83490951161529758, 0.84371012450450744, 0.89140604665527201, 0.8914060466879653, 0.82189140330512922, 0.82189140329414789], \"Term\": [\"&\", \":\", \":\", \"abbreviations\", \"abbreviations\", \"ability\", \"accent\", \"accent\", \"acceptable\", \"acceptable\", \"acceptable\", \"accident\", \"according\", \"accurately\", \"acronym\", \"actors\", \"adjective\\u2014right\", \"affect\", \"almost\", \"also\", \"alternative\", \"always\", \"america\", \"american\", \"american\", \"answering\", \"apostrophe\", \"appalachian\", \"applied\", \"appropriate\", \"appropriate\", \"appropriate\", \"ask\", \"assume\", \"assure\", \"attention\", \"authoritative\", \"b\", \"based\", \"begging\", \"best\", \"better\", \"better\", \"betwixt\", \"bless\", \"bloggers\", \"borrowed\", \"bother\", \"bracket\", \"british\", \"bus\", \"buyer*\", \"c\", \"capability\", \"capitalize\", \"capitalized\", \"capitalized\", \"car\", \"case\", \"case\", \"certainly\", \"cling\", \"closely\", \"closer\", \"color\", \"colour\", \"come\", \"come\", \"come\", \"comma\", \"comma\", \"common\", \"common\", \"compared\", \"connect\", \"contemporary\", \"contemporary\", \"context\", \"context\", \"contracted\", \"contraction\", \"contraction\", \"conversational\", \"correct\", \"correct\", \"correct\", \"correct\", \"correct\", \"correct\", \"correct\", \"correct:\", \"correct:\", \"correct:\", \"correctly\", \"correctly\", \"could\", \"course\", \"creating\", \"creation\", \"dash\", \"dates\", \"dear\", \"details\", \"determine\", \"determiner\", \"diagnostic\", \"dictionaries\", \"die\", \"differ\", \"difference\", \"difference\", \"difference\", \"difference\", \"differences\", \"different\", \"distinguish\", \"documents\", \"doubled\", \"dry\", \"dying\", \"e\", \"e\", \"effect\", \"elizabethan\", \"email\", \"employee\", \"employee\", \"employees\", \"end\", \"end\", \"end\", \"end\", \"ending\", \"ending\", \"english\", \"english\", \"english\", \"ensure\", \"especially\", \"especially\", \"etc\", \"etymology\", \"ever\", \"ever\", \"everyone\", \"exclamation\", \"expression\", \"fame\", \"family\", \"favourite\", \"federal\", \"fewer\", \"find\", \"followed\", \"football\", \"foreign\", \"form\", \"format\", \"format\", \"forms\", \"free\", \"freshman\", \"full\", \"g\", \"g\", \"gender\", \"gender\", \"genetic\", \"gerund\", \"gerund\", \"gerund\", \"give\", \"given\", \"god\", \"good\", \"good\", \"good!\", \"got\", \"got\", \"government\", \"great\", \"guide\", \"guys\", \"haskell\", \"hyphenated\", \"id\", \"identify\", \"important\", \"in/with\", \"in/with\", \"inactivate\", \"incorrect\", \"infinitive\", \"infinitive\", \"instead\", \"instead\", \"instead\", \"instead\", \"insure\", \"internet\", \"introductory\", \"item\", \"japanese\", \"k\", \"know\", \"l\", \"last\", \"latin\", \"lay\", \"learn\", \"less\", \"less\", \"lie\", \"like\", \"like\", \"line\", \"line\", \"list\", \"lowercase\", \"made\", \"manual\", \"mark\", \"matter\", \"may\", \"mean\", \"mean\", \"means\", \"means\", \"means\", \"might\", \"mind\", \"much\", \"name\", \"name\", \"native\", \"neutral\", \"neutral\", \"new\", \"non\", \"nothing\", \"nouns\", \"nouns\", \"objective\", \"octopus\", \"offensive\", \"ok\", \"one\", \"one\", \"online\", \"ordering\", \"origin/reason\", \"orthographies\", \"oxen\", \"part\", \"parts\", \"passive\", \"pay\", \"pedantically\", \"people\", \"people\", \"per\", \"period\", \"person\", \"persons\", \"photographs\", \"phrase\", \"phrase\", \"phrase\", \"phrases\", \"please\", \"plural\", \"plural\", \"pluralize\", \"pluralized\", \"pluralized\", \"politely\", \"possession\", \"prefix\", \"preposition\", \"presume\", \"professional\", \"pronoun\", \"pronounce\", \"pronounced\", \"proper\", \"proper\", \"proposals\", \"punctuation\", \"put\", \"q\", \"quality\", \"question\", \"question\", \"question\", \"question\", \"questions\", \"quotation\", \"quote\", \"r\", \"rather\", \"really\", \"really\", \"really\", \"reasonably\", \"recognized\", \"recommendations\", \"referring\", \"regard\", \"regulatory\", \"related\", \"relatives\", \"reliably\", \"relief\", \"remorse\", \"replenish\", \"respectively\", \"result\", \"retarded\", \"rhyme\", \"right\", \"roll\", \"rule\", \"rule\", \"rules\", \"run\", \"r\\u00e9sum\\u00e9\", \"said\", \"salutation\", \"say\", \"say\", \"semicolon\", \"semicolon\", \"sentence\", \"sentence\", \"sentence\", \"sentences\", \"sentences\", \"shall\", \"short\", \"signed\", \"significant\", \"singular\", \"singular\", \"singular\", \"soccer\", \"software\", \"something\", \"spaghetti\", \"spare\", \"speak\", \"speaking\", \"speaks\", \"specially\", \"speech\", \"speech\", \"spelling\", \"splitting\", \"spoken\", \"squiggly\", \"standard\", \"standing\", \"start\", \"start\", \"style\", \"style\", \"suggest\", \"suppose\", \"synonym\", \"talking\", \"taught\", \"technical\", \"tell\", \"tests\", \"thehulk66\", \"thought\", \"three\", \"title\", \"title\", \"together\", \"together\", \"trebble\", \"truth\", \"try\", \"tutorial\", \"twice\", \"two\", \"um\", \"untranslatables\", \"up:\", \"uppercase\", \"us\", \"us\", \"usage\", \"usage\", \"used\", \"used\", \"used\", \"used\", \"using\", \"ven\", \"verb\", \"versa\", \"versus\", \"versus\", \"vice\", \"voice\", \"vowels\", \"vs\", \"vs\", \"vs\", \"vs\", \"vs\", \"way\", \"way\", \"ways\", \"well\", \"well\", \"well\", \"what\\u2019s\", \"whether\", \"word\", \"word\", \"word\", \"word\", \"word\", \"words\", \"words\", \"words\", \"words\", \"work\", \"would\", \"would\", \"write\", \"write\", \"write:\", \"writing\", \"writing\", \"writing\", \"written\", \"written\", \"wrong\", \"wrong\", \"\\u2014which\", \"\\u2019ll\", \"\\u201cr\\u201d\", \"\\u201cu\\u201d\", \"\\u201cwhom\\u201d\", \"\\u201cwho\\u201d\"]}, \"mdsDat\": {\"y\": [-0.056351425268638435, 0.14457026462289876, 0.043442449204471482, -0.021851428964515817, -0.11180323320910056, -0.086284759441050241, 0.028978852277301539, -0.00895105581989597, 0.061182781464002849, 0.0070675551345263255], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [12.813595270762496, 12.674017827673135, 11.810882923420001, 10.470367341410473, 10.04028856513607, 9.8511310705932331, 9.2265853999353098, 9.0379604435839607, 7.3980919866698578, 6.6770791708154613], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"x\": [-0.12756458410399005, 0.10575762213025129, -0.1189309369522507, 0.047481446608200591, 0.071636777015403219, 0.087388734527230755, -0.065256019343135546, -0.039086948117326846, 0.010060499185556081, 0.02851340905006073]}, \"R\": 30, \"lambda.step\": 0.01, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"Term\": [\"sentence\", \"english\", \"vs\", \"difference\", \"e\", \"acceptable\", \"instead\", \"name\", \"used\", \"appropriate\", \"come\", \"said\", \"mark\", \"start\", \"versus\", \"title\", \"ending\", \"plural\", \"way\", \"great\", \"bus\", \"usage\", \"employee\", \"try\", \"question\", \"g\", \"compared\", \"different\", \"words\", \"word\", \"standing\", \"car\", \"accident\", \"die\", \"forms\", \"oxen\", \"cling\", \"dying\", \"pedantically\", \"passive\", \"respectively\", \"voice\", \"identify\", \"um\", \"accurately\", \"reliably\", \"contracted\", \"ven\", \"assure\", \"ensure\", \"insure\", \"truth\", \"introductory\", \"phrases\", \"persons\", \"twice\", \"tell\", \"person\", \"something\", \"talking\", \"g\", \"people\", \"vs\", \"line\", \"e\", \"word\", \"pluralized\", \"correct:\", \"said\", \"work\", \"email\", \"english\", \"closely\", \"two\", \"dash\", \"related\", \"connect\", \"recommendations\", \"non\", \"spoken\", \"nothing\", \"details\", \"speaking\", \"native\", \"bloggers\", \"photographs\", \"regulatory\", \"salutation\", \"dear\", \"rhyme\", \"spare\", \"almost\", \"thought\", \"applied\", \"dictionaries\", \"authoritative\", \"quality\", \"bother\", \"write\", \"used\", \"sentences\", \"semicolon\", \"always\", \"ok\", \"foreign\", \"\\u201cwho\\u201d\", \"id\", \"what\\u2019s\", \"r\\u00e9sum\\u00e9\", \"guys\", \"\\u201cwhom\\u201d\", \"adjective\\u2014right\", \"using\", \"splitting\", \"made\", \"proposals\", \"determiner\", \"fame\", \"hyphenated\", \"rules\", \"relief\", \"apostrophe\", \"capitalize\", \"give\", \"lowercase\", \"parts\", \"matter\", \"uppercase\", \"referring\", \"run\", \"dry\", \"know\", \"employee\", \"come\", \"phrase\", \"words\", \"word\", \"got\", \"like\", \"say\", \"correctly\", \"rule\", \"compared\", \"different\", \"c\", \"k\", \"bless\", \"god\", \"q\", \"alternative\", \"america\", \"objective\", \"\\u2014which\", \"suggest\", \"regard\", \"spaghetti\", \"also\", \"conversational\", \"japanese\", \"prefix\", \"part\", \"pronounce\", \"begging\", \"borrowed\", \"lay\", \"answering\", \"lie\", \"questions\", \"soccer\", \"football\", \"usage\", \"contemporary\", \"used\", \"correct\", \"in/with\", \"case\", \"would\", \"try\", \"name\", \"difference\", \"technical\", \"manual\", \"b\", \"documents\", \"federal\", \"government\", \"given\", \"family\", \"put\", \"item\", \"list\", \"last\", \"course\", \"attention\", \"mind\", \"certainly\", \"speaks\", \"freshman\", \"new\", \"pay\", \"color\", \"capability\", \"colour\", \"ability\", \"octopus\", \"shall\", \"\\u2019ll\", \"plural\", \"writing\", \"comma\", \"format\", \"us\", \"up:\", \"signed\", \"three\", \"vowels\", \"based\", \"orthographies\", \"differ\", \"write:\", \"thehulk66\", \"&\", \"might\", \"diagnostic\", \"latin\", \"may\", \"distinguish\", \"tests\", \"right\", \"taught\", \"roll\", \"squiggly\", \"acronym\", \"bracket\", \"actors\", \"pluralize\", \"r\", \"professional\", \"specially\", \"according\", \"please\", \"per\", \"way\", \"especially\", \"better\", \"wrong\", \"context\", \"nouns\", \":\", \"proper\", \"written\", \"common\", \"sentence\", \"full\", \"quotation\", \"much\", \"quote\", \"punctuation\", \"period\", \"pronoun\", \"followed\", \"verb\", \"incorrect\", \"pronounced\", \"ask\", \"politely\", \"versus\", \"start\", \"ending\", \"e\", \"instead\", \"neutral\", \"ever\", \"acceptable\", \"gender\", \"infinitive\", \"rule\", \"contraction\", \"really\", \"singular\", \"gerund\", \"g\", \"correct\", \"end\", \"come\", \"great\", \"bus\", \"good!\", \"tutorial\", \"learn\", \"haskell\", \"expression\", \"origin/reason\", \"suppose\", \"dates\", \"vice\", \"versa\", \"employees\", \"differences\", \"presume\", \"rather\", \"best\", \"assume\", \"everyone\", \"affect\", \"result\", \"effect\", \"inactivate\", \"creation\", \"fewer\", \"creating\", \"significant\", \"important\", \"title\", \"less\", \"vs\", \"correct:\", \"mean\", \"good\", \"capitalized\", \"mark\", \"free\", \"online\", \"ordering\", \"exclamation\", \"find\", \"recognized\", \"guide\", \"reasonably\", \"standard\", \"software\", \"speak\", \"whether\", \"determine\", \"form\", \"possession\", \"short\", \"preposition\", \"genetic\", \"relatives\", \"could\", \"appropriate\", \"neutral\", \"style\", \"accent\", \"one\", \"correctly\", \"semicolon\", \"together\", \"means\", \"question\", \"well\", \"end\", \"used\", \"elizabethan\", \"appalachian\", \"ways\", \"british\", \"closer\", \"etc\", \"trebble\", \"betwixt\", \"\\u201cu\\u201d\", \"offensive\", \"\\u201cr\\u201d\", \"internet\", \"synonym\", \"buyer*\", \"spelling\", \"remorse\", \"retarded\", \"etymology\", \"doubled\", \"replenish\", \"untranslatables\", \"favourite\", \"l\", \"less\", \"american\", \"abbreviations\", \"contemporary\", \"speech\", \"acceptable\", \"english\", \"correct\"], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.7244999999999999, 1.7244999999999999, 1.7244999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4968999999999999, 1.4533, 1.4483999999999999, 1.3411, 1.4389000000000001, 1.0646, 0.76190000000000002, 1.1000000000000001, 0.82840000000000003, 1.8280000000000001, 1.732, 1.732, 1.6718999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.5025999999999999, 1.4521999999999999, 1.1698, 1.1063000000000001, 1.1316999999999999, 1.7948, 1.7948, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5613999999999999, 1.5228999999999999, 1.4871000000000001, 1.2790999999999999, 1.1061000000000001, 0.80840000000000001, 1.1586000000000001, 1.1362000000000001, 1.1362000000000001, 1.1867000000000001, 1.1677999999999999, 1.9052, 1.9052, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6667000000000001, 1.6214, 1.3016000000000001, 0.9163, 0.16880000000000001, 1.2655000000000001, 1.2611000000000001, 1.2398, 1.9401999999999999, 1.8168, 1.7175, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6981999999999999, 1.6597999999999999, 0.99060000000000004, 1.2890999999999999, 1.3027, 1.2638, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.7239, 1.6734, 1.3214999999999999, 1.2957000000000001, 1.3214999999999999, 1.3145, 1.3145, 1.3214999999999999, 1.3214999999999999, 1.3145, 1.3145, 2.0364, 1.7790999999999999, 1.7790999999999999, 1.7790999999999999, 1.7790999999999999, 1.7790999999999999, 1.7790999999999999, 1.7790999999999999, 1.7790999999999999, 1.7790999999999999, 1.7790999999999999, 1.7790999999999999, 1.7790999999999999, 1.7790999999999999, 1.7338, 1.7303999999999999, 1.7113, 1.6882999999999999, 1.5517000000000001, 1.3949, 1.3662000000000001, 1.3604000000000001, 1.3556999999999999, 1.3556999999999999, 1.3556999999999999, 1.3472999999999999, 1.079, 1.0697000000000001, 1.0528999999999999, 1.0409999999999999, 0.91369999999999996, 0.84630000000000005, 0.63890000000000002, 2.0358999999999998, 2.0358999999999998, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7892999999999999, 1.7306999999999999, 1.4167000000000001, 0.89890000000000003, 1.0627, 1.373, 1.3539000000000001, 1.3539000000000001, 2.2227999999999999, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.9697, 1.6803999999999999, 1.5566, 1.5541, 1.5362, 1.5362, 1.5362, 1.5277000000000001, 1.5237000000000001, 1.2416, 1.0325, 1.2363999999999999, 1.008, 0.52959999999999996, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 2.0476000000000001, 1.6338999999999999, 1.6244000000000001, 1.6171, 1.6171, 1.5934999999999999, 1.5775999999999999, 0.9052, 0.48420000000000002], \"Freq\": [5.0, 6.0, 8.0, 5.0, 3.0, 3.0, 4.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 4.0, 1.3539901185766654, 1.3539901167400226, 1.3539901165463875, 0.70923291974432034, 0.70923291969427382, 0.70923291968601454, 0.70923291962844959, 0.70923291961452617, 0.70923291938611077, 0.70923291925866183, 0.70923291884795481, 0.70923291882467765, 0.70923291880964645, 0.70923291880177908, 0.70923291868123728, 0.70923291858940762, 0.70923291827850476, 0.70923291818696343, 0.7092329177743536, 0.70923291758023876, 0.70923291754191098, 0.70923291750710349, 0.7092329174912817, 0.70923291748305939, 0.70923291741018557, 0.70923291712481928, 0.70923291708962954, 0.70923291707871827, 0.70923291649667941, 0.70923291628817209, 1.3539977906792211, 1.3539917336049807, 3.9325823741285602, 1.3539964803653219, 1.3539901013144269, 1.3540298965330435, 0.70923422256476054, 0.70923348212346493, 1.976969019801565, 1.3392370772076954, 1.3392370771606597, 4.5279194029076448, 0.7015051359097344, 0.70150513583834961, 0.70150513574017082, 0.70150513571601181, 0.70150513555638971, 0.70150513539708692, 0.70150513534528569, 0.70150513532212055, 0.70150513506235734, 0.70150513505483569, 0.70150513504645418, 0.70150513502180656, 0.70150513494414868, 0.70150513481826526, 0.7015051347782747, 0.7015051346937109, 0.70150513468325681, 0.70150513467804765, 0.70150513467823594, 0.70150513463612485, 0.70150513461727859, 0.70150513458789676, 0.70150513454287744, 0.70150513453480234, 0.70150513449708218, 0.70150513449771279, 1.3392409386787048, 1.9769834043461831, 0.70150600511411576, 0.70150573086551626, 1.3073994236451383, 1.3073994161390521, 0.68482826953673637, 0.68482826948297493, 0.68482826941609343, 0.68482826921480111, 0.68482826920762396, 0.68482826909472727, 0.68482826903901639, 0.68482826892060267, 0.68482826886579562, 0.68482826883525838, 0.68482826882300163, 0.68482826874086289, 0.68482826868751012, 0.68482826860518542, 0.68482826857518597, 0.68482826856242762, 0.6848282684607343, 0.68482826845493328, 0.68482826840918276, 0.68482826837688782, 0.68482826808577413, 0.68482826783950834, 0.68482826775715377, 0.68482826769216565, 0.68482826766354554, 0.68482826740516611, 0.68482826723273249, 0.68482826721762391, 1.3074067586284113, 1.9299992007185665, 1.3074174686285385, 1.3074191956098973, 1.3074285291192687, 0.68483034229230277, 0.68482932638142779, 0.68482864356227235, 0.68482856308638784, 0.68482852564710639, 1.2675599736504906, 1.2675599708864724, 0.66395998641145271, 0.66395998635352227, 0.66395998627234221, 0.66395998621346997, 0.66395998618130347, 0.66395998586487903, 0.66395998584369942, 0.66395998573065651, 0.66395998570323544, 0.6639599856147762, 0.66395998529569955, 0.663959985283742, 0.66395998515170318, 0.66395998500254971, 0.66395998488882768, 0.66395998464523109, 0.66395998438608195, 0.66395998433854242, 0.66395998432040815, 0.66395998429945402, 0.66395998364518638, 0.66395998313789806, 0.66395998307977011, 0.66395998234717324, 0.66395998042166271, 0.66395997926279315, 1.2675688680483712, 0.66395635243007833, 1.2675681985286662, 0.66396325381689669, 0.66396274013909362, 0.66396058350950959, 0.66396026184179846, 1.2413238545760508, 1.8324472725262539, 3.0147799124607393, 0.65021725975339095, 0.65021725964192956, 0.65021725932891072, 0.65021725930923435, 0.65021725924869922, 0.65021725923305829, 0.65021725920566609, 0.65021725886511295, 0.65021725867243085, 0.65021725847379475, 0.65021725844383771, 0.65021725768307337, 0.65021725760440829, 0.65021725756452875, 0.65021725745545045, 0.65021725735852542, 0.65021725735408542, 0.65021725719929169, 0.65021725720904566, 0.65021725678611741, 0.65021725606549574, 0.65021725575310529, 0.65021725575868872, 0.65021725574440925, 0.65021725568907285, 0.65021725271592079, 0.65021725188364154, 1.2413342771004112, 0.65022041105325867, 0.650219827514816, 0.65021889244659004, 0.65021840044830415, 0.65897861112020084, 0.658978611080137, 0.65897861077892639, 0.65897861068542396, 0.65897861066256969, 0.65897861064533847, 0.65897861061537344, 0.65897861054986895, 0.65897861052304441, 0.65897861038910999, 0.65897861033297433, 0.65897861027199656, 0.65897861022555804, 0.65897861019399062, 0.6589786100965962, 0.658978609952935, 0.65897860987601897, 0.6589786091781572, 0.65897860898718086, 0.65897860894507865, 0.65897860880071035, 0.65897860860260604, 0.65897860837376343, 0.6589786082251623, 0.65897860815524467, 0.65897860803044106, 0.65897860786254958, 0.65897860722074875, 0.6589786071927205, 0.65897860716732348, 1.2580556330021395, 0.65898335514221074, 0.65898264612014634, 0.65898087414697792, 0.65898080656342251, 0.65898080552876948, 0.65898063461089051, 0.65898063303598409, 0.6589801377376574, 0.65897967733317919, 4.1667022741532476, 0.64554150259958698, 0.64554150257424914, 0.6455415025617568, 0.6455415024287513, 0.64554150228015061, 0.64554150212466876, 0.64554150199183502, 0.6455415010328257, 0.64554150087040374, 0.64554150047600112, 0.64554150004598043, 0.64554149938605254, 0.64554149868437993, 1.2324244142506491, 1.2323429899560159, 1.2324034553704744, 1.8192197439633011, 1.8192736956400408, 0.64554103925756223, 0.64554329874846295, 1.2323357938534889, 0.64554515510090271, 0.64554421115631233, 0.64554125962487974, 0.64554162076139665, 0.64554518328527499, 0.64555191454219274, 0.64554967081389591, 0.64553451883534285, 1.2324389796952009, 0.64554618536011232, 0.64554461790616879, 1.20719469477293, 1.2071946927815367, 0.6323400782181644, 0.63234007814452275, 0.63234007801760017, 0.63234007794661262, 0.63234007687498484, 0.63234007676967086, 0.63234007615347942, 0.63234007593417785, 0.6323400758773523, 0.63234007584659957, 0.63234007576687323, 0.6323400757105756, 0.63234007566873018, 0.63234007565877715, 0.63234007539153669, 0.63234007499772793, 0.6323400743801123, 0.63234007425496785, 0.63234007409036719, 0.63234007402799497, 0.63234007402426973, 0.63234007400895065, 0.63234007386174818, 0.63234007362252265, 0.63234007163718664, 0.6323400714419789, 1.2072029880656752, 0.63233574034084272, 1.7825761621966345, 0.63234395403142163, 0.6323435054821992, 0.63234320414085077, 0.63234319983971499, 1.1615277832886155, 0.60841931465710974, 0.608419314656233, 0.60841931452663645, 0.60841931449593989, 0.60841931449571118, 0.60841931444854025, 0.6084193144188762, 0.60841931436723096, 0.60841931426840212, 0.60841931411267258, 0.60841931395128701, 0.60841931394374948, 0.60841931393478954, 0.60841931362962953, 0.60841931349815526, 0.6084193134651773, 0.60841931236112046, 0.60841930880211226, 0.60841930761314145, 0.60841929572946263, 1.1615423212361708, 0.60841975076496169, 0.60842036446492243, 0.6084214197663208, 0.60842135836892097, 0.60841905086674852, 0.60841879580956471, 0.60842723672000409, 0.60842522236033225, 0.60843543808522715, 0.60842743287962697, 0.6084208530865356, 0.60842078543107225, 0.58045748037252765, 0.58045748026841737, 0.58045748017630938, 0.58045748006270548, 0.58045747989953012, 0.58045747987212348, 0.58045747963097272, 0.58045747944838444, 0.58045747940709924, 0.58045747912532097, 0.58045747912457413, 0.58045747896057975, 0.58045747872808606, 0.58045747866228159, 0.58045747860146768, 0.58045747843911, 0.58045747841368267, 0.58045747559651095, 0.58045747445540219, 0.58045747442307205, 0.58045747421523652, 0.58045747347555687, 0.58045747336701659, 0.58046145797982274, 0.58046124552939549, 0.58046097301180877, 0.58046065677783687, 0.58045991103346284, 1.1081613581276295, 1.108150204001265, 0.58046751545976072], \"Total\": [5.0, 6.0, 8.0, 5.0, 3.0, 3.0, 4.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 4.0, 1.8836490005627446, 1.8836490004095414, 1.8836490003915141, 1.2388917993426574, 1.2388917993371367, 1.2388917993358481, 1.2388917993340189, 1.2388917993275981, 1.2388917993004482, 1.238891799297076, 1.238891799257499, 1.2388917992585335, 1.2388917992514354, 1.2388917992632009, 1.2388917992432156, 1.2388917992362749, 1.2388917992072412, 1.2388917992011363, 1.2388917991588713, 1.2388917991483277, 1.2388917991365525, 1.2388917991398201, 1.2388917991398642, 1.2388917991334518, 1.2388917991349664, 1.2388917991110087, 1.2388917991050907, 1.2388917991019357, 1.2388917990575787, 1.2388917990189066, 2.4705056026971919, 2.4827205812299544, 8.0275889054532126, 2.5062203757681822, 3.6442148066143698, 4.9324869269837182, 1.8424918724742463, 2.4173462493755395, 2.5073304301418036, 1.8695984860503283, 1.8695984860256181, 6.712707728500158, 1.23186654206098, 1.2318665420475403, 1.2318665420439818, 1.2318665420482253, 1.2318665420254102, 1.23186654201215, 1.2318665420115984, 1.2318665420094339, 1.2318665419910624, 1.2318665419812953, 1.2318665419858412, 1.2318665419830239, 1.2318665419752373, 1.2318665419638832, 1.231866541967199, 1.2318665419576065, 1.2318665419532129, 1.2318665419504502, 1.2318665419557913, 1.2318665419520607, 1.2318665419554344, 1.2318665419488468, 1.2318665419436978, 1.231866541941623, 1.2318665419457457, 1.2318665419578501, 2.4731986827652959, 4.8424952499311837, 1.8309380609138963, 1.78497509070549, 1.8392769110758262, 1.8392769106878546, 1.2167057545520765, 1.2167057545461497, 1.2167057545433895, 1.2167057545343134, 1.2167057545303488, 1.2167057545243423, 1.2167057545298932, 1.2167057545172368, 1.2167057545244333, 1.2167057545147095, 1.2167057545095816, 1.2167057545066833, 1.2167057545078839, 1.2167057545071824, 1.2167057545064774, 1.2167057544994395, 1.2167057544781577, 1.2167057544850539, 1.2167057544843702, 1.2167057544950524, 1.2167057544695612, 1.2167057544556443, 1.2167057544412698, 1.2167057544365201, 1.2167057544478734, 1.216705754423151, 1.2167057544370437, 1.2167057544327411, 2.4141320912876871, 3.6934598540013592, 3.0806087630087085, 3.6624898718533609, 4.9324869269837182, 1.8203058076492342, 1.8614629178955684, 1.8614629421665652, 1.7698142570397208, 1.8035616823915848, 1.8013345782108214, 1.8013345781367056, 1.1977345881157506, 1.197734588123845, 1.1977345881147745, 1.1977345881206056, 1.1977345881207517, 1.197734588116588, 1.1977345881047878, 1.1977345881153623, 1.1977345881056047, 1.1977345880982138, 1.1977345880998505, 1.1977345880990868, 1.1977345880892436, 1.1977345880931927, 1.1977345880826751, 1.1977345880875088, 1.1977345880772876, 1.1977345880791912, 1.1977345880782886, 1.1977345880743167, 1.1977345880680117, 1.1977345880558599, 1.1977345880356862, 1.1977345880288921, 1.197734587989669, 1.1977345880075621, 2.3924413637554558, 1.7254227512084861, 4.8424952499311837, 5.3566383495813925, 1.7888412465332935, 1.7968060587936192, 1.8354665164452333, 1.7763478009587179, 2.9665256420666641, 5.3900651794427539, 1.1852411994919145, 1.1852411994938357, 1.1852411994870173, 1.1852411994822418, 1.1852411994890015, 1.1852411994984349, 1.185241199487479, 1.1852411995043532, 1.1852411994935064, 1.1852411994918, 1.1852411994884164, 1.1852411994999028, 1.1852411994883365, 1.1852411994871614, 1.1852411994914043, 1.1852411994850471, 1.1852411994922272, 1.1852411994813195, 1.1852411995060401, 1.1852411994942345, 1.1852411994985466, 1.1852411994928416, 1.1852411995042091, 1.1852411994907617, 1.1852411994803473, 1.1852411994946308, 1.1852411995023506, 2.351202705637653, 2.4048530272406103, 1.7843126310805077, 1.7600958625081922, 1.8299982971659843, 1.1932060642880891, 1.1932060642894036, 1.1932060642887585, 1.1932060642854949, 1.1932060642785842, 1.1932060642870854, 1.1932060642808906, 1.1932060642879385, 1.1932060642893523, 1.1932060642846136, 1.1932060642770079, 1.1932060642714628, 1.1932060642823048, 1.1932060642804667, 1.1932060642768467, 1.1932060642681415, 1.1932060642676341, 1.1932060642678353, 1.1932060642553735, 1.1932060642618443, 1.1932060642317028, 1.1932060642513342, 1.1932060642495161, 1.1932060642484816, 1.1932060642420379, 1.1932060642565674, 1.1932060642279125, 1.1932060642366313, 1.1932060642272426, 1.1932060642419524, 2.3958774786167245, 1.784312728821899, 1.8309377476824753, 1.7843126958165996, 1.7968060377088981, 1.7968060377348787, 1.7843126926391557, 1.7843126926100332, 1.7968060427983144, 1.7968060462471791, 5.8929647059912993, 1.1809905112108339, 1.1809905112067178, 1.1809905112068484, 1.1809905112067842, 1.180990511214248, 1.1809905112116654, 1.1809905112167465, 1.1809905112254044, 1.180990511226429, 1.1809905112324013, 1.1809905112315309, 1.1809905112244625, 1.1809905112536219, 2.3589528302574161, 2.3669238928098935, 2.4126030295164389, 3.6442148066143698, 4.1779126949985539, 1.7340989541294829, 1.7845904500363483, 3.4268276039513834, 1.803561445342174, 1.8035615027649485, 1.8035616823915848, 1.8187224447091885, 2.3784161870931246, 2.4006014052905251, 2.4412929115029236, 2.4705056026971919, 5.3566383495813925, 3.001426818664136, 3.6934598540013592, 1.7438438341097178, 1.7438438341782185, 1.1689892160786166, 1.1689892160790003, 1.1689892160838093, 1.1689892160894715, 1.16898921612266, 1.168989216133701, 1.1689892161469517, 1.1689892161570137, 1.1689892161504365, 1.1689892161620019, 1.1689892161552087, 1.1689892161649169, 1.168989216160589, 1.168989216170679, 1.1689892161830706, 1.1689892162017279, 1.1689892161973827, 1.1689892162084248, 1.168989216216215, 1.168989216215552, 1.1689892162181841, 1.1689892162069255, 1.1689892162182551, 1.1689892162395541, 1.1689892162853601, 1.1689892163216227, 2.3664143020658819, 1.6966774808249987, 8.0275889054532126, 2.4173462493755395, 1.7725890347657107, 1.8067208181153283, 1.8067208180546765, 1.7003515369668809, 1.1472430675387968, 1.1472430675436625, 1.1472430675532292, 1.1472430675537055, 1.1472430675593621, 1.1472430675574621, 1.1472430675644614, 1.1472430675783307, 1.147243067569552, 1.1472430675729832, 1.1472430675982532, 1.1472430676019025, 1.1472430675962373, 1.1472430676264944, 1.1472430676448566, 1.1472430676427363, 1.1472430677207885, 1.1472430680073789, 1.1472430680899381, 1.1472430691220643, 2.924937235473855, 1.7340989541294829, 1.7383495968880502, 1.7698139596356715, 1.769813967216197, 1.7698142570397208, 1.78497509070549, 1.7919989558234501, 2.3760809366046622, 2.9288044583552333, 2.3885740146682513, 3.001426818664136, 4.8424952499311837, 1.1218232180446424, 1.1218232180576555, 1.121823218069399, 1.121823218088523, 1.1218232181073646, 1.121823218108883, 1.1218232181429242, 1.1218232181605019, 1.1218232181793217, 1.1218232182130503, 1.1218232182204659, 1.1218232182369767, 1.1218232182643357, 1.1218232182757082, 1.1218232182885934, 1.1218232183106003, 1.1218232183215218, 1.1218232187163406, 1.1218232188695547, 1.1218232188634296, 1.121823218876091, 1.1218232189868327, 1.1218232190124469, 1.6966774808249987, 1.7129293670733308, 1.7254227057206761, 1.7254227512084861, 1.7665798800024457, 3.4268276039513834, 6.712707728500158, 5.3566383495813925], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.9594, -3.9594, -3.9594, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -3.9594, -3.9594, -2.8932000000000002, -3.9594, -3.9594, -3.9594, -4.6060999999999996, -4.6060999999999996, -3.5699999999999998, -3.9594, -3.9594, -2.7412999999999998, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -4.6060999999999996, -3.9594, -3.5699999999999998, -4.6060999999999996, -4.6060999999999996, -3.9129999999999998, -3.9129999999999998, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -3.9129999999999998, -3.5234999999999999, -3.9129999999999998, -3.9129999999999998, -3.9129999999999998, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -4.5595999999999997, -3.8233999999999999, -3.8233999999999999, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -3.8233999999999999, -4.4701000000000004, -3.8233999999999999, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -4.4701000000000004, -3.8024, -3.4129, -2.9150999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -3.8024, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4489999999999998, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -3.77, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -4.4165999999999999, -2.5070000000000001, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -3.7250999999999999, -3.7252000000000001, -3.7250999999999999, -3.3357000000000001, -3.3355999999999999, -4.3718000000000004, -4.3716999999999997, -3.7252000000000001, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3716999999999997, -4.3718000000000004, -3.7250999999999999, -4.3716999999999997, -4.3716999999999997, -3.7250999999999999, -3.7250999999999999, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -3.7250999999999999, -4.3718000000000004, -3.3353999999999999, -4.3716999999999997, -4.3718000000000004, -4.3718000000000004, -4.3718000000000004, -3.5634999999999999, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -3.5634999999999999, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.2100999999999997, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -4.1546000000000003, -3.508, -3.508, -4.1546000000000003]}};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el163221404346454025765648584978\", ldavis_el163221404346454025765648584978_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el163221404346454025765648584978\", ldavis_el163221404346454025765648584978_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el163221404346454025765648584978\", ldavis_el163221404346454025765648584978_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "8      12.813595        1       1 -0.127565 -0.056351\n",
       "5      12.674018        1       2  0.105758  0.144570\n",
       "9      11.810883        1       3 -0.118931  0.043442\n",
       "3      10.470367        1       4  0.047481 -0.021851\n",
       "7      10.040289        1       5  0.071637 -0.111803\n",
       "1       9.851131        1       6  0.087389 -0.086285\n",
       "2       9.226585        1       7 -0.065256  0.028979\n",
       "4       9.037960        1       8 -0.039087 -0.008951\n",
       "6       7.398092        1       9  0.010060  0.061183\n",
       "0       6.677079        1      10  0.028513  0.007068, topic_info=     Category      Freq             Term     Total  loglift  logprob\n",
       "term                                                                \n",
       "286   Default  5.000000         sentence  5.000000  30.0000  30.0000\n",
       "282   Default  6.000000          english  6.000000  29.0000  29.0000\n",
       "262   Default  8.000000               vs  8.000000  28.0000  28.0000\n",
       "13    Default  5.000000       difference  5.000000  27.0000  27.0000\n",
       "365   Default  3.000000                e  3.000000  26.0000  26.0000\n",
       "47    Default  3.000000       acceptable  3.000000  25.0000  25.0000\n",
       "68    Default  4.000000          instead  4.000000  24.0000  24.0000\n",
       "100   Default  2.000000             name  2.000000  23.0000  23.0000\n",
       "272   Default  4.000000             used  4.000000  22.0000  22.0000\n",
       "327   Default  2.000000      appropriate  2.000000  21.0000  21.0000\n",
       "227   Default  3.000000             come  3.000000  20.0000  20.0000\n",
       "214   Default  2.000000             said  2.000000  19.0000  19.0000\n",
       "248   Default  1.000000             mark  1.000000  18.0000  18.0000\n",
       "331   Default  2.000000            start  2.000000  17.0000  17.0000\n",
       "95    Default  2.000000           versus  2.000000  16.0000  16.0000\n",
       "188   Default  2.000000            title  2.000000  15.0000  15.0000\n",
       "185   Default  2.000000           ending  2.000000  14.0000  14.0000\n",
       "122   Default  2.000000           plural  2.000000  13.0000  13.0000\n",
       "333   Default  2.000000              way  2.000000  12.0000  12.0000\n",
       "34    Default  1.000000            great  1.000000  11.0000  11.0000\n",
       "337   Default  1.000000              bus  1.000000  10.0000  10.0000\n",
       "294   Default  2.000000            usage  2.000000   9.0000   9.0000\n",
       "191   Default  2.000000         employee  2.000000   8.0000   8.0000\n",
       "17    Default  1.000000              try  1.000000   7.0000   7.0000\n",
       "330   Default  2.000000         question  2.000000   6.0000   6.0000\n",
       "129   Default  2.000000                g  2.000000   5.0000   5.0000\n",
       "354   Default  1.000000         compared  1.000000   4.0000   4.0000\n",
       "265   Default  1.000000        different  1.000000   3.0000   3.0000\n",
       "83    Default  3.000000            words  3.000000   2.0000   2.0000\n",
       "51    Default  4.000000             word  4.000000   1.0000   1.0000\n",
       "...       ...       ...              ...       ...      ...      ...\n",
       "206   Topic10  0.580457      appalachian  1.121823   2.0476  -4.1546\n",
       "180   Topic10  0.580457             ways  1.121823   2.0476  -4.1546\n",
       "133   Topic10  0.580457          british  1.121823   2.0476  -4.1546\n",
       "213   Topic10  0.580457           closer  1.121823   2.0476  -4.1546\n",
       "266   Topic10  0.580457              etc  1.121823   2.0476  -4.1546\n",
       "0     Topic10  0.580457          trebble  1.121823   2.0476  -4.1546\n",
       "20    Topic10  0.580457          betwixt  1.121823   2.0476  -4.1546\n",
       "70    Topic10  0.580457              u  1.121823   2.0476  -4.1546\n",
       "357   Topic10  0.580457        offensive  1.121823   2.0476  -4.1546\n",
       "232   Topic10  0.580457              r  1.121823   2.0476  -4.1546\n",
       "120   Topic10  0.580457         internet  1.121823   2.0476  -4.1546\n",
       "177   Topic10  0.580457          synonym  1.121823   2.0476  -4.1546\n",
       "304   Topic10  0.580457           buyer*  1.121823   2.0476  -4.1546\n",
       "77    Topic10  0.580457         spelling  1.121823   2.0476  -4.1546\n",
       "119   Topic10  0.580457          remorse  1.121823   2.0476  -4.1546\n",
       "237   Topic10  0.580457         retarded  1.121823   2.0476  -4.1546\n",
       "118   Topic10  0.580457        etymology  1.121823   2.0476  -4.1546\n",
       "200   Topic10  0.580457          doubled  1.121823   2.0476  -4.1546\n",
       "287   Topic10  0.580457        replenish  1.121823   2.0476  -4.1546\n",
       "207   Topic10  0.580457  untranslatables  1.121823   2.0476  -4.1546\n",
       "362   Topic10  0.580457        favourite  1.121823   2.0476  -4.1546\n",
       "103   Topic10  0.580457                l  1.121823   2.0476  -4.1546\n",
       "74    Topic10  0.580461             less  1.696677   1.6339  -4.1546\n",
       "134   Topic10  0.580461         american  1.712929   1.6244  -4.1546\n",
       "43    Topic10  0.580461    abbreviations  1.725423   1.6171  -4.1546\n",
       "184   Topic10  0.580461     contemporary  1.725423   1.6171  -4.1546\n",
       "270   Topic10  0.580460           speech  1.766580   1.5935  -4.1546\n",
       "47    Topic10  1.108161       acceptable  3.426828   1.5776  -3.5080\n",
       "282   Topic10  1.108150          english  6.712708   0.9052  -3.5080\n",
       "123   Topic10  0.580468          correct  5.356638   0.4842  -4.1546\n",
       "\n",
       "[385 rows x 6 columns], token_table=      Topic      Freq             Term\n",
       "term                                  \n",
       "42        6  0.838078                &\n",
       "334       5  0.560440                :\n",
       "334       6  0.560440                :\n",
       "43        4  0.579568    abbreviations\n",
       "43       10  0.579568    abbreviations\n",
       "212       5  0.843710          ability\n",
       "143       3  0.565031           accent\n",
       "143       9  0.565031           accent\n",
       "47        4  0.291815       acceptable\n",
       "47        7  0.291815       acceptable\n",
       "47       10  0.291815       acceptable\n",
       "229       1  0.530884         accident\n",
       "233       6  0.838078        according\n",
       "145       1  0.807173       accurately\n",
       "318       6  0.838078          acronym\n",
       "358       6  0.838078           actors\n",
       "197       3  0.821891  adjectiveright\n",
       "12        8  0.855440           affect\n",
       "260       2  0.811776           almost\n",
       "166       4  0.834910             also\n",
       "291       4  0.834910      alternative\n",
       "101       3  0.543692           always\n",
       "176       4  0.834910          america\n",
       "134       5  0.583795         american\n",
       "134      10  0.583795         american\n",
       "164       4  0.834910        answering\n",
       "238       3  0.821891       apostrophe\n",
       "206      10  0.891406      appalachian\n",
       "254       2  0.811776          applied\n",
       "327       2  0.341888      appropriate\n",
       "...     ...       ...              ...\n",
       "346       3  0.821891           whats\n",
       "342       9  0.871655          whether\n",
       "51        1  0.202737             word\n",
       "51        2  0.202737             word\n",
       "51        3  0.202737             word\n",
       "51        5  0.202737             word\n",
       "51        8  0.202737             word\n",
       "83        1  0.273038            words\n",
       "83        3  0.273038            words\n",
       "83        4  0.273038            words\n",
       "83        8  0.273038            words\n",
       "54        2  0.534874             work\n",
       "41        2  0.544821            would\n",
       "41        4  0.544821            would\n",
       "65        2  0.404335            write\n",
       "65        4  0.404335            write\n",
       "198       6  0.838078           write:\n",
       "90        1  0.415826          writing\n",
       "90        5  0.415826          writing\n",
       "90        8  0.415826          writing\n",
       "217       4  0.556543          written\n",
       "217       6  0.556543          written\n",
       "75        5  0.560440            wrong\n",
       "75        6  0.560440            wrong\n",
       "25        4  0.834910           which\n",
       "161       5  0.843710              ll\n",
       "232      10  0.891406              r\n",
       "70       10  0.891406              u\n",
       "264       3  0.821891           whom\n",
       "148       3  0.821891            who\n",
       "\n",
       "[448 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[9, 6, 10, 4, 8, 2, 3, 5, 7, 1])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(ldamodel,corpus,dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'difference', 0.14372220635414124),\n",
       " (u'english', 0.10943149030208588),\n",
       " (u'words', 0.09991291165351868),\n",
       " (u'sentence', -0.00631171278655529),\n",
       " (u'vs', -0.015746433287858963),\n",
       " (u'instead', -0.024223752319812775),\n",
       " (u'word', -0.03956236317753792),\n",
       " (u'come', -0.04033884406089783),\n",
       " (u'e', -0.07122258841991425),\n",
       " (u'used', -0.09349112212657928)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(allposts, size=200)\n",
    "model.most_similar(positive = ['correct'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## References\n",
    "\n",
    "* https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
    "* LDA Viz - http://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf\n",
    "* This dashboard @ https://github.com/dhruvaray/soml\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
