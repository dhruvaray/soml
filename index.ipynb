{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "\n",
    "Popular question and answer (qna) site -  stackoverflow (+ their sister sites) allows for download of monthly data dumps from https://archive.org/details/stackexchange.\n",
    "\n",
    "With this data, can we classify the questions/answers based on\n",
    "\n",
    "* Conceptual v/s howto question \n",
    "* Beginner v/s intermediate v/s hard/trick\n",
    "* A particular question is associated with another question in terms of the next things to do or perhaps the pre-requisites?\n",
    "* Predict the next question a user may ask based on this current search\n",
    "\n",
    "The taxanomy could be a useful layout of the land for a student of the area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema\n",
    "\n",
    "The schema for their data is located @ https://ia800500.us.archive.org/22/items/stackexchange/readme.txt.\n",
    "    \n",
    "Unfortunately, the data is dumped in an XML format and there is preliminary effort to convert that data into CSV format. We have written a converter (convert2csv.py) for the tables of interest.\n",
    "\n",
    "The schemas for the tables of interest are shown below.\n",
    "\n",
    "\n",
    "## Posts\n",
    "-----------\n",
    "- Id\n",
    "- PostTypeId\n",
    "  - 1: Question\n",
    "  - 2: Answer\n",
    "- ParentID (only present if PostTypeId is 2)\n",
    "- AcceptedAnswerId (only present if PostTypeId is 1)\n",
    "- CreationDate\n",
    "- Score\n",
    "- ViewCount\n",
    "- Body\n",
    "- OwnerUserId\n",
    "- LastEditorUserId\n",
    "- LastEditorDisplayName=\"Jeff Atwood\"\n",
    "- LastEditDate=\"2009-03-05T22:28:34.823\"\n",
    "- LastActivityDate=\"2009-03-11T12:51:01.480\"\n",
    "- CommunityOwnedDate=\"2009-03-11T12:51:01.480\"\n",
    "- ClosedDate=\"2009-03-11T12:51:01.480\"\n",
    "- Title=\n",
    "- Tags=\n",
    "- AnswerCount\n",
    "- CommentCount\n",
    "- FavoriteCount\n",
    "\n",
    "## Comments\n",
    "---------------------------\n",
    "- Id\n",
    "- PostId\n",
    "- Score\n",
    "- Text, e.g.: \"@Stu Thompson: Seems possible to me - why not try it?\"\n",
    "- CreationDate, e.g.:\"2008-09-06T08:07:10.730\"\n",
    "- UserId\n",
    "\n",
    "## Post History\n",
    "---------------------------\n",
    "- Id\n",
    "- PostHistoryTypeId\n",
    "    - 1: Initial Title - The first title a question is asked with.\n",
    "    - 2: Initial Body - The first raw body text a post is submitted with.\n",
    "    - 3: Initial Tags - The first tags a question is asked with.\n",
    "    - 4: Edit Title - A question's title has been changed.\n",
    "    - 5: Edit Body - A post's body has been changed, the raw text is stored here as markdown.\n",
    "    - 6: Edit Tags - A question's tags have been changed.\n",
    "    - 7: Rollback Title - A question's title has reverted to a previous version.\n",
    "    - 8: Rollback Body - A post's body has reverted to a previous version - the raw text is stored here.\n",
    "    - 9: Rollback Tags - A question's tags have reverted to a previous version.\n",
    "    - 10: Post Closed - A post was voted to be closed.\n",
    "    - 11: Post Reopened - A post was voted to be reopened.\n",
    "    - 12: Post Deleted - A post was voted to be removed.\n",
    "    - 13: Post Undeleted - A post was voted to be restored.\n",
    "    - 14: Post Locked - A post was locked by a moderator.\n",
    "    - 15: Post Unlocked - A post was unlocked by a moderator.\n",
    "    - 16: Community Owned - A post has become community owned.\n",
    "    - 17: Post Migrated - A post was migrated.\n",
    "    - 18: Question Merged - A question has had another, deleted question merged into itself.\n",
    "    - 19: Question Protected - A question was protected by a moderator\n",
    "    - 20: Question Unprotected - A question was unprotected by a moderator\n",
    "    - 21: Post Disassociated - An admin removes the OwnerUserId from a post.\n",
    "    - 22: Question Unmerged - A previously merged question has had its answers and votes restored.\n",
    "- PostId\n",
    "- RevisionGUID: At times more than one type of history record can be recorded by a single action.  \n",
    "- CreationDate: \"2009-03-05T22:28:34.823\"\n",
    "- UserId\n",
    "- UserDisplayName: populated if a user has been removed and no longer referenced by user Id\n",
    "- Comment: This field will contain the comment made by the user who edited a post\n",
    "- Text: A raw version of the new value for a given revision. \n",
    "- CloseReasonId\n",
    "    - 1: Exact Duplicate - This question covers exactly the same ground as earlier questions on this topic; its answers may be merged with another identical question.\n",
    "    - 2: off-topic\n",
    "    - 3: subjective\n",
    "    - 4: not a real question\n",
    "    - 7: too localized\n",
    "       \n",
    "       \n",
    "## Users\n",
    "---------------------------\n",
    " - Id\n",
    " - Reputation\n",
    " - CreationDate\n",
    " - DisplayName\n",
    " - EmailHash\n",
    " - LastAccessDate\n",
    " - WebsiteUrl\n",
    " - Location\n",
    " - Age\n",
    " - AboutMe\n",
    " - Views\n",
    " - UpVotes\n",
    " - DownVotes\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion from XML to CSV\n",
    "\n",
    "Run python convert2csv.py to convert each of the xml files to their CSV equivalents. For columns/attributes which contain textual data, the converter encodes them with base64 encoding so that handling of quotes and special characters (separators) is avoided. \n",
    "\n",
    "When the data is read back into the dataframe, the corresponding decode (from base64) needs to happen. The converter also creates a sample file of 100 rows for each xml data dump converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import base64\n",
    "import math\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>When you want to connect two closely related s...</td>\n",
       "      <td>Should I use a semicolon or a dash to connect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>In most languages, gender plays a much more im...</td>\n",
       "      <td>When referring to a noun, when does the gender...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>What is the difference in usage between abilit...</td>\n",
       "      <td>Difference between \"ability\" and \"capability\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>\"Into\" (one word) and \"in to\" (two words) are ...</td>\n",
       "      <td>When should \"into\" be used rather than \"in to,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Body  \\\n",
       "89  When you want to connect two closely related s...   \n",
       "93  In most languages, gender plays a much more im...   \n",
       "98  What is the difference in usage between abilit...   \n",
       "99  \"Into\" (one word) and \"in to\" (two words) are ...   \n",
       "\n",
       "                                                Title  \n",
       "89  Should I use a semicolon or a dash to connect ...  \n",
       "93  When referring to a noun, when does the gender...  \n",
       "98      Difference between \"ability\" and \"capability\"  \n",
       "99  When should \"into\" be used rather than \"in to,...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = pd.read_csv('posts.sample.csv').dropna(subset=['Body','Title'])\n",
    "posts['Body'] = posts['Body'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "posts['Title'] = posts['Title'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "posts[['Body','Title']].tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that we have stripped out the html formatting tags with BeautifulSoup before reassigning back to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>I think you need to edit the title of your que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>It's correct when you're accessing a method of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yes, I would think in almost any context where...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Would you say `It can certainly be \"acceptable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@serg555: Would you expect anything less on a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                               Text\n",
       "0      9  I think you need to edit the title of your que...\n",
       "1     12  It's correct when you're accessing a method of...\n",
       "2      2  Yes, I would think in almost any context where...\n",
       "3      0  Would you say `It can certainly be \"acceptable...\n",
       "4      4  @serg555: Would you expect anything less on a ..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.read_csv('comments.sample.csv').dropna()\n",
    "comments['Text'] = comments['Text'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "comments[['Score','Text']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-08-05T19:48:13.987</td>\n",
       "      <td>I think you need to edit the title of your que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-08-05T20:01:43.273</td>\n",
       "      <td>It's correct when you're accessing a method of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-08-05T20:10:25.270</td>\n",
       "      <td>Yes, I would think in almost any context where...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-08-05T20:11:23.957</td>\n",
       "      <td>Would you say `It can certainly be \"acceptable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-08-05T20:12:43.500</td>\n",
       "      <td>@serg555: Would you expect anything less on a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CreationDate                                               Text\n",
       "0  2010-08-05T19:48:13.987  I think you need to edit the title of your que...\n",
       "1  2010-08-05T20:01:43.273  It's correct when you're accessing a method of...\n",
       "2  2010-08-05T20:10:25.270  Yes, I would think in almost any context where...\n",
       "3  2010-08-05T20:11:23.957  Would you say `It can certainly be \"acceptable...\n",
       "4  2010-08-05T20:12:43.500  @serg555: Would you expect anything less on a ..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posthistory = pd.read_csv('posthistory.sample.csv').dropna(subset=['Text'])\n",
    "posthistory['Text'] = posthistory['Text'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "comments[['CreationDate','Text']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>AboutMe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on the server farm</td>\n",
       "      <td>Hi, I'm not really a person.\\nI'm a background...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corvallis, OR</td>\n",
       "      <td>Developer on the Stack Overflow team.  Find me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Developer on the Stack Overflow team.\\nWas dub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>I design stuff for Stack Exchange. Also a prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>I slip my front end into the back end, and the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Location                                            AboutMe\n",
       "0  on the server farm  Hi, I'm not really a person.\\nI'm a background...\n",
       "1       Corvallis, OR  Developer on the Stack Overflow team.  Find me...\n",
       "2        New York, NY  Developer on the Stack Overflow team.\\nWas dub...\n",
       "3         Raleigh, NC  I design stuff for Stack Exchange. Also a prof...\n",
       "4          California  I slip my front end into the back end, and the..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('users.sample.csv').dropna(subset=['AboutMe','Location'])\n",
    "users['AboutMe'] = users['AboutMe'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "users['Location'] = users['Location'].apply(lambda x : BeautifulSoup(base64.b64decode(x),\"lxml\").get_text())\n",
    "users[['Location','AboutMe']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further cleansing\n",
    "\n",
    "* Remove (html) tags & carriage returns from the Text field\n",
    "* Remove stop words (pick up the nltk stop words)\n",
    "* Use PorterStemmer to stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn']\n"
     ]
    }
   ],
   "source": [
    "#global\n",
    "p_stemmer = PorterStemmer()\n",
    "stop_words = stopwords.words('english')\n",
    "print stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'use', u'use', u'could', u'right', u'context']\n",
      "[u\"doesn't\", u'\"quint\"', u'mean', u'\"five\"', u'meaning', u'\"quintessential\"']\n",
      "[u'correct', u'use', u'two', u'words,', u'context', u'one', u'used', u'rather']\n",
      "[u'think', u'folk', u'happily', u'use', u'either', u'\"while\"', u'\"whilst\"', u\"i've\", u'vague', u'recollection', u'one', u'time', u'\"while\"', u'indicated', u'passing', u'time', u'\"whilst\"', u'essentially', u'\"whereas\"', u'\"although\"', u'using', u'time', u'passing', u'walking', u'street', u'sun', u'shining', u'whilst', u'whereas/although', u'whilst', u'walking', u'street', u'often', u'prefer', u'hop', u'views']\n",
      "[u'may', u'coming', u'tomorrow', u'might', u'coming', u'tomorrow', u'could', u'use', u'\"may\"', u'&', u'\"might\"']\n",
      "[u'feel', u'uncomfortable', u'saying', u'sentences', u'like', u'following:', u'\"i\\'ve', u'car\"', u'instead', u'\"i', u'car\"\"they\\'ve', u'great', u'time\"', u'instead', u'\"they', u'great', u'time\"\"he\\'s', u'pen\"', u'instead', u'\"he', u'pen\"etci', u'ask', u'read', u'sort', u'thing', u'book', u'correct', u'rule', u'use', u'forms', u'formal', u'setting']\n",
      "[u'concrete', u'rules', u'say', u'words', u'(parts', u'speech)', u'title', u'start', u'capital', u'letter', u'would', u'correct', u'capitalization', u'title', u'question']\n",
      "[u'like', u'many', u'others,', u'commonly', u'find', u'ending', u'sentence', u'preposition', u'yes,', u'makes', u'cringe', u'usually', u'rewrite', u'sentence,', u'sometimes', u'(in', u'emails)', u'live', u'to,', u'know', u'keep', u'fighting', u'one,', u'okay', u'circumstances']\n",
      "[u\"i've\", u'heard', u'lots', u'varying', u'histories', u'term', u'\"ok\"', u'evidence', u'true', u'origin', u'term']\n",
      "[u'would', u'proper', u'say', u'freshman', u'students,', u'freshmen,', u'freshmen', u'students', u'edit:it', u'worth', u'noting', u'since', u'learned', u'acceptable', u'educational', u'circles', u'use', u'term', u'\"first-year', u'students\"', u'instead', u'\"freshmen\"']\n",
      "[u'baseball,', u'inning', u\"team's\", u'(or', u\"teams',\", u'depending', u'context)', u'turn', u'bat', u'game', u'consists', u'9', u'innings', u'cricket,', u'innings', u\"team's\", u'turn', u'bat,', u'game', u'consists', u'2', u'4', u'innings', u'difference', u'singular', u'usage', u'arise', u'\"inning\"', u'could', u'conceivably', u'derived', u'like', u'\"outing\":', u'outing', u'time', u'one', u'out,', u'inning', u'time', u'one', u'(to', u'bat/to', u'play)', u'singular', u'\"innings\"', u'come']\n",
      "[u'grew', u'speaking', u'british', u'english', u'words', u'learnt', u'occasionally', u'marked', u'papers,', u'despite', u'english', u'words', u'words', u'like', u'betwixt,', u'trebble,', u'learnt', u'acceptable', u'papers', u'english', u'classes', u'professors', u'america,', u'specifically', u'texas']\n",
      "[u'possible', u'duplicate:is', u'correct', u'use', u'\\u201cpunctuation', u'outside', u'quotations\\u201d,', u'\\u201cinside', u'\\u201d', u\"i've\", u'heard', u'always', u'place', u'ending', u'punctuation', u'inside', u'quotes,', u'matter', u'cases', u'appropriate', u'sentence', u'end', u'\"']\n",
      "[u'better', u'say:', u\"what's\", u'wrong', u'something', u\"what's\", u'wrong', u'something']\n",
      "[u'pronoun', u'use', u'gender-neutral', u'pronoun', u'student', u'save', u'questions', u'end', u'student', u'save', u'questions', u'end']\n",
      "[u\"i've\", u'seen', u'contraction', u'two', u'words', u\"can't\", u'see', u\"wouldn't\", u'possible', u'contract', u'twice', u'possible', u'punctuated', u'update:', u'ok,', u'sum', u'answers', u'farthis', u'appears', u'spoken', u'british', u'american', u'englishit', u'one', u'lower', u'registers', u'englisheven', u'spoken', u'way', u'sometimes,', u\"isn't\", u'really', u'written', u'double', u'contraction,', u'except', u'written', u'speech', u'fiction', u'googling', u'wiktionary,', u'appears', u'written', u'forms', u'old', u'british', u'words,', u'often', u'nautical', u'like', u\"fo'c'sle\"]\n",
      "[u'never', u'figure', u'whether', u'use', u'people', u'use', u'colloquially,', u'that\\u2019s', u'correct', u'what\\u2019s', u'rule', u'using', u'correctly']\n",
      "[u'growing', u'up,', u'ever', u'said', u'something', u'similar', u'\"can', u'go', u'store', u'joe', u'\",', u'mom', u'would', u'correct', u'\"may', u'go', u'store', u'joe', u'\"', u'\"may', u'\"', u'typical', u'way', u'ask', u'question', u'politely', u'specific', u'grew', u'mom', u'learned']\n",
      "[u'difference', u'gerund', u'participle']\n",
      "[u'appropriate', u'use', u'opposed']\n",
      "[u'heard', u'starting', u'sentence', u'however', u'wrong', u'grounds', u'view', u'still', u'held', u'majority', u'pedants', u'would', u'suggest', u'changinghowever,', u'people', u'beginning', u'doubt', u'tosome', u'people,', u'however,', u'\\u2026orsome', u'people', u'are,', u'however,', u'beginning', u'\\u2026']\n",
      "[u'one', u'correctly', u'use', u'semicolon', u'probably', u'one', u'difficult', u'punctuation', u'marks', u'master', u'opinion']\n",
      "[u'apostrophical', u'query:a)', u'buyers', u'remorseb)', u'buyer', u'remorsec)', u\"buyer's\", u'remorsed)', u\"buyers'\", u'remorsemy', u'guess', u'b', u'c,', u'seems', u'like', u'example', u'talking', u'remorse', u'one', u'specific', u'buyer,', u'since', u'collective', u'term', u'happens', u'universally,', u'perhaps', u'possessive', u'plural', u'accurate', u'suppose', u'there\\u2019s', u'potential', u'it\\u2019s', u'context-sensitive', u'decision,', u'deciding', u'whether', u'talking', u'exactly', u'one', u'buyer', u'buyers', u'general']\n",
      "[u'know', u'use', u'lay', u'use', u'lie,', u'different', u'forms', u'verb', u\"i'm\", u'always', u'getting', u'confused']\n",
      "[u'want', u'connect', u'two', u'closely', u'related', u'sentences,', u'use', u'semicolon', u'dash', u'(you', u'also', u'use', u'dash', u'kinds', u'non-sentential', u'relations)', u'would', u'choose', u'whether', u'use', u'semicolon', u'dash']\n",
      "[u'languages,', u'gender', u'plays', u'much', u'important', u'role', u'english', u'nevertheless,', u'possible', u'refer', u'noun', u'using', u'gender', u'ship', u'launched', u'4', u'october', u'1853', u'tayleur', u'left', u'liverpool', u'19', u'january', u'1854,', u'maiden', u'voyage', u'one', u'know', u'\"ship\"', u'feminine', u'masculine', u'nouns']\n",
      "[u'difference', u'usage', u'ability', u'capability']\n",
      "[u'\"into\"', u'(one', u'word)', u'\"in', u'to\"', u'(two', u'words)', u'frequently', u'confused', u'situations', u'former', u'used', u'latter']\n"
     ]
    }
   ],
   "source": [
    "class SentenceTokens():\n",
    "    def __init__(self,df,field):\n",
    "        self.field = field\n",
    "        self.df = df\n",
    "    \n",
    "    def __iter__(self):\n",
    "      for index, row in self.df.iterrows():\n",
    "         raw_sentence = row[self.field].replace('\\n','').lower()\n",
    "         raw_tokens = filter(None, re.split(\"[ ?.]+\",raw_sentence))\n",
    "         #stem_tokens = [p_stemmer.stem(tok) for tok in raw_tokens]\n",
    "         yield [tok for tok in raw_tokens if not tok in stop_words]\n",
    "\n",
    "#all posts is a list of (list of tokens). The inner list of tokens is created once for each post\n",
    "allposts = SentenceTokens(posts,'Body')\n",
    "\n",
    "for p in allposts:\n",
    "    print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How frequently each term occurs within each document? We construct a document-term matrix.\n",
    "dictionary = corpora.Dictionary(allposts)\n",
    "#print(dictionary.token2id) maps ids to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (1, 1), (2, 1), (3, 1)]\n"
     ]
    }
   ],
   "source": [
    "#bag of words\n",
    "corpus = [dictionary.doc2bow(text) for text in allposts]\n",
    "#corpus, is a list of vectors equal to the number of documents. \n",
    "#In each document vector is a series of tuples. \n",
    "print(corpus[0])\n",
    "#(term ID, term frequency) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=30, id2word = dictionary, passes=100)\n",
    "\n",
    "#num_topics: required. An LDA model requires the user to determine how many topics should be generated. \n",
    "#id2word: required. The LdaModel class requires our previous dictionary to map ids to strings.\n",
    "#passes: optional. The number of laps the model will take through corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16, u'0.064*opposed + 0.064*appropriate + 0.064*use'), (19, u'0.003*words + 0.003*english + 0.003*learnt'), (28, u'0.029*\" + 0.029*correct + 0.029*use'), (20, u'0.042*innings + 0.028*use + 0.028*turn'), (18, u'0.003*said + 0.003*up, + 0.003*\",'), (26, u'0.003*one + 0.003*talking + 0.003*buyers'), (21, u'0.085*one + 0.043*use + 0.043*correctly'), (12, u'0.003*spoken + 0.003*written + 0.003*british'), (5, u'0.081*end + 0.081*save + 0.081*pronoun'), (23, u'0.003*said + 0.003*up, + 0.003*\",')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=10, num_words=3))\n",
    "#Each generated topic is separated by a comma.\n",
    "#Within each topic are the three most probable words to appear in that topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## References\n",
    "\n",
    "* https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
