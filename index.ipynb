{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problem\n",
    "\n",
    "Popular question and answer (qna) site -  stackoverflow (+ their sister sites) allows for download of monthly data dumps from https://archive.org/details/stackexchange.\n",
    "\n",
    "With this data, can we classify the questions/answers based on\n",
    "\n",
    "* Identify similar questions\n",
    "* A particular question is associated with another question in terms of the next things to do or perhaps the pre-requisites?\n",
    "* Predict the next question a user may ask based on this current search\n",
    "\n",
    "The taxanomy could be a useful layout of the land for a student of the area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Schema\n",
    "\n",
    "The schema for their data is located @ https://ia800500.us.archive.org/22/items/stackexchange/readme.txt.\n",
    "    \n",
    "Unfortunately, the data is dumped in an XML format and there is preliminary effort to convert that data into CSV format. We have written a converter (convert2csv.py) for the tables of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion from XML to CSV\n",
    "\n",
    "Run python convert2csv.py to convert each of the xml files to their CSV equivalents. For columns/attributes which contain textual data, the converter encodes them with base64 encoding so that handling of quotes and special characters (separators) is avoided. \n",
    "\n",
    "When the data is read back into the dataframe, the corresponding decode (from base64) needs to happen. The converter also creates a sample file of 100 rows for each xml data dump converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora, models,similarities\n",
    "from gensim.models import word2vec, doc2vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from pprint import pprint                        # pretty-printer\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "SAMPLE_SIZE = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "* Load post title and body from post files\n",
    "* Load post test from history files\n",
    "* Load user info from user files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when should i use can  when should i use could...</td>\n",
       "      <td>when do i use  can  or  could</td>\n",
       "      <td>word-choice  tenses  politeness  subjunctive-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doesn t  quint  mean  five    what does that h...</td>\n",
       "      <td>where does the  quint  in  quintessential  com...</td>\n",
       "      <td>etymology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body  \\\n",
       "0  when should i use can  when should i use could...   \n",
       "1  doesn t  quint  mean  five    what does that h...   \n",
       "\n",
       "                                               Title  \\\n",
       "0                    when do i use  can  or  could     \n",
       "1  where does the  quint  in  quintessential  com...   \n",
       "\n",
       "                                                Tags  \n",
       "0   word-choice  tenses  politeness  subjunctive-...  \n",
       "1                                         etymology   "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = pd.read_csv('data/posts.csv.gz',compression='gzip',nrows=SAMPLE_SIZE).dropna(subset=['Body','Title'])\n",
    "posts['Tags'] = posts['Tags'].apply(lambda x : x.replace('<',' ').replace('>',' '))\n",
    "posts[['Body','Title', 'Tags']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#comments = pd.read_csv('data/comments.csv.gz',compression='gzip',nrows=SAMPLE_SIZE).dropna()\n",
    "#comments[['Score','Text']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when could i use can  or when can i use could ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when do i could  can     could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doesn t  quint  mean five   what does that hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>where does the  quint  in quintessential come ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>which is the correct use of these two words an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  when could i use can  or when can i use could ...\n",
       "1                  when do i could  can     could   \n",
       "3  doesn t  quint  mean five   what does that hav...\n",
       "4  where does the  quint  in quintessential come ...\n",
       "6  which is the correct use of these two words an..."
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posthistory = pd.read_csv('data/posthistory.csv.gz',compression='gzip',nrows=SAMPLE_SIZE).dropna(subset=['Text'])\n",
    "posthistory[['Text']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>AboutMe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>on the server farm</td>\n",
       "      <td>hi  i m not really a person  i m a background ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corvallis  or</td>\n",
       "      <td>developer on the stack overflow team   find me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new york  ny</td>\n",
       "      <td>developer on the stack overflow team  was dubb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raleigh  nc</td>\n",
       "      <td>i design stuff for stack exchange  also a prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>california</td>\n",
       "      <td>i slip my front end into the back end  and the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Location                                            AboutMe\n",
       "0  on the server farm  hi  i m not really a person  i m a background ...\n",
       "1       corvallis  or  developer on the stack overflow team   find me...\n",
       "2        new york  ny  developer on the stack overflow team  was dubb...\n",
       "3         raleigh  nc  i design stuff for stack exchange  also a prof...\n",
       "4          california  i slip my front end into the back end  and the..."
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('data/users.csv.gz',compression='gzip',nrows=SAMPLE_SIZE).dropna(subset=['AboutMe','Location'])\n",
    "users[['Location','AboutMe']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further cleansing\n",
    "\n",
    "* Remove (html) tags & carriage returns from the Text field\n",
    "* Remove stop words (pick up the nltk stop words)\n",
    "* Use PorterStemmer to stem words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StopWords():\n",
    "    def __init__(self):\n",
    "        #p_stemmer = PorterStemmer()\n",
    "        self.stop_words = stopwords.words('english')\n",
    "        self.stop_words.append('use')\n",
    "\n",
    "    def remove(self, sentence):\n",
    "        raw_tokens = filter(None, re.split(\";+| +|,+|\\?+|\\*+\",sentence))\n",
    "        return [tok for tok in raw_tokens if not tok in self.stop_words and len(tok) > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#global\n",
    "#p_stemmer = PorterStemmer()\n",
    "#stop_words = stopwords.words('english')\n",
    "#stop_words.append('use')\n",
    "stop_words = StopWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentenceTokens():\n",
    "    def __init__(self,df,field):\n",
    "        self.field = field\n",
    "        self.df = df\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for index, row in self.df.iterrows():\n",
    "            raw_sentence = row[self.field]\n",
    "            yield stop_words.remove(raw_sentence)\n",
    "\n",
    "            #raw_tokens = filter(None, re.split(\"[ ]+\",raw_sentence))\n",
    "            #stem_tokens = [p_stemmer.stem(tok) for tok in raw_tokens]\n",
    "            #yield [tok for tok in raw_tokens if not tok in stop_words and len(tok) > 1 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all posts is a list of (list of tokens). The inner list of tokens is created once for each post\n",
    "allposts = SentenceTokens(posts,'Title')\n",
    "#print([p for p in allposts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How frequently each term occurs within each document? We construct a document-term matrix.\n",
    "dictionary = corpora.Dictionary(allposts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bag of words\n",
    "#corpus is a list of vectors equal to the number of documents. \n",
    "#In each document vector is a series of tuples. \n",
    "corpus = [dictionary.doc2bow(post) for post in allposts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Bag of Words\n",
    "* Take a sample question\n",
    "* Remove stop words\n",
    "* Convert into a vector using bag of words\n",
    "* Search vector using LSI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Where', 'quint', 'quintessential', 'come']\n"
     ]
    }
   ],
   "source": [
    "# Find similar questions by converting it into vector\n",
    "samples = ['Where does the quint in quintessential come from?',\n",
    "           'Where does goodness me come from?']\n",
    "\n",
    "sampleIndex = 0\n",
    "sampleVector = dictionary.doc2bow(stop_words.remove(samples[sampleIndex]))\n",
    "pprint(stop_words.remove(samples[sampleIndex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decide number of topics based on factors in a vector\n",
    "numberOfTopics = len(sampleVector)\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=numberOfTopics)\n",
    "\n",
    "# convert the query (sample vector) to LSI space\n",
    "vec_lsi = lsi[sampleVector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   100.000% :  tit for tat    where does this come from \n",
      "   100.000% : where does the  quint  in  quintessential  come from \n",
      "   100.000% : where does  ta   come from \n",
      "   100.000% : are  come round  and  visit  interchangeable \n",
      "   100.000% : where did the  juices  in  creative juices  come from \n",
      "   100.000% : where does  santa  in santa claus come from \n",
      "   100.000% : where does  can t be arsed  come from \n",
      "    99.999% : where does  hot damn   come from \n",
      "    99.998% : should i use  will  or  would  when i suggest that something will would come in handy \n",
      "    99.997% : where did the saying  bite the dust  come from \n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus]) \n",
    "\n",
    "# perform a similarity query against the corpus\n",
    "sims = index[vec_lsi]\n",
    "\n",
    "# Sort in descending order - highest matching percentage on top\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "sims_list = list(enumerate(sims))\n",
    "\n",
    "# Show top 10 matches only\n",
    "for i in range(0, 10):\n",
    "    docid = sims_list[i][1][0]\n",
    "    matchPercentage = sims_list[i][1][1]\n",
    "#     print(str(matchPercentage * 100) + \" : \" + posts.iloc[docid]['Title'])\n",
    "    print(\"{:10.3f}% : {}\".format(matchPercentage * 100, posts.iloc[docid]['Title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=4, id2word = dictionary, passes=30)\n",
    "\n",
    "#num_topics: required. An LDA model requires the user to determine how many topics should be generated. \n",
    "#id2word: required. The LdaModel class requires our previous dictionary to map ids to strings.\n",
    "#passes: optional. The number of laps the model will take through corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, u'0.030*sentence + 0.021*correct + 0.014*meaning'),\n",
       " (1, u'0.032*difference + 0.031*vs + 0.015*say'),\n",
       " (2, u'0.028*mean + 0.018*meaning + 0.015*versus'),\n",
       " (3, u'0.038*word + 0.028*english + 0.015*mean')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(num_topics=5, num_words=3)\n",
    "def understand(num_topics, num_words):\n",
    "    return ldamodel.print_topics(num_topics, num_words)\n",
    "    \n",
    "#Each generated topic is separated by a comma.\n",
    "#Within each topic are the three most probable words to appear in that topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el223221396349203060009717630586\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el223221396349203060009717630586_data = {\"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 3, 2], \"token.table\": {\"Topic\": [2, 3, 3, 4, 1, 1, 4, 2, 3, 3, 3, 1, 2, 4, 2, 2, 4, 2, 3, 4, 4, 3, 4, 1, 2, 1, 2, 4, 4, 4, 1, 1, 2, 3, 4, 2, 3, 1, 4, 1, 3, 4, 2, 1, 4, 4, 3, 2, 2, 1, 2, 1, 4, 2, 1, 1, 4, 4, 1, 3, 4, 2, 3, 1, 4, 4, 3, 2, 3, 1, 2, 1, 4, 1, 1, 3, 1, 2, 4, 4, 3, 4, 3, 3, 1, 2, 1, 1, 3, 4, 1, 1, 3, 4, 1, 2, 2, 1, 3, 4, 1, 2, 3, 1, 1, 3, 2, 4, 2, 3, 4, 1, 1, 2, 3, 3, 4, 1, 1, 2, 3, 4, 4, 3, 1, 1, 2, 3, 4, 2, 1, 3, 4, 2, 3, 4, 1, 3, 4, 1, 1, 3, 4, 3, 1, 3, 4, 2, 4, 3, 4, 2, 1, 2, 3, 4, 2, 3, 2, 2, 1, 2, 3, 4, 1, 3, 1, 4, 1, 4, 1, 4, 3, 2, 1, 4, 2, 3, 4, 3, 1, 3, 2, 2, 3, 4, 3, 4, 1, 1, 4, 2, 2, 2, 4, 2, 1, 1, 2, 1, 3, 4, 3, 4, 1, 1, 4, 3, 1, 2, 3, 4, 2, 1, 2, 3, 4, 3, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 1, 3, 3, 3, 1, 2, 4, 2, 3, 4, 2, 3, 3, 1, 2, 3, 1, 2, 3, 4, 3, 1, 2, 3, 4, 4, 1, 4], \"Freq\": [0.76725145262530359, 0.23017543578759106, 0.98965190829624783, 0.89493096177266551, 0.9674883315747953, 0.39867941422572306, 0.5798973297828699, 0.9716066873981557, 0.88377537010134899, 0.96153313292818998, 0.95889188289983518, 0.92288523987624582, 0.9791874071749066, 0.96431113627685194, 0.94472914322846213, 0.9486394459409665, 0.91635131143537085, 0.10621531402002157, 0.15932297103003235, 0.71695336963514555, 0.91937261200387621, 0.92789902087152598, 0.9401233108106698, 0.98374991510570331, 0.96623622101363105, 0.52145629585816466, 0.27314377402094342, 0.19865001746977703, 0.90064490243221551, 0.95355959294183212, 0.94648834863484843, 0.15015646152214621, 0.5521882778556344, 0.18890651610850651, 0.10656265011249084, 0.90854981998847428, 0.98530009446597777, 0.35341321154427052, 0.6472145560810737, 0.15072233865328025, 0.25120389775546709, 0.55264857506202758, 0.99271171832440641, 0.23413122406522055, 0.74921991700870572, 0.89724922542168029, 0.92528319528826586, 0.9878778377798465, 0.94652019016554889, 0.82126530372422457, 0.17564633663466075, 0.3535702064933024, 0.63642637168794425, 0.97417864641389962, 0.9337731977014081, 0.97324964305131278, 0.96207536960669815, 0.91784003915488777, 0.98009771503734855, 0.94730957395640103, 0.98577991059915648, 0.24506402775481406, 0.75969848603992352, 0.96533248585642661, 0.93050264757887702, 0.93391261141332771, 0.98565642201029424, 0.97795832983422259, 0.97404777106465101, 0.2485406471488652, 0.74562194144659555, 0.20109213974751475, 0.80436855899005899, 0.95767909590444789, 0.98747880824627032, 0.98709643183430096, 0.7798305606869782, 0.20521856860183635, 0.94017868302038532, 0.87972213709463098, 0.82740744196021265, 0.13790124032670212, 0.98566090287489783, 0.91605206345442436, 0.97939585218204683, 0.98239741165093186, 0.97249877532867746, 0.73823979333289957, 0.24986577620498138, 0.93533980243590542, 0.95569599580382114, 0.94215831893773128, 0.89583729258003986, 0.94999911353760114, 0.99489231757260865, 0.97344912272138973, 0.96520762990753584, 0.34705817176197873, 0.51689514943273429, 0.1366080037786512, 0.21942183084928193, 0.36881541781049515, 0.41550091373587433, 0.99356262934378103, 0.95960850508604512, 0.93706962805146699, 0.34013087685581911, 0.65191751397365327, 0.21169519208643492, 0.77621570431692799, 0.942128258356277, 0.98297156593496082, 0.19932846494928491, 0.52323722049187293, 0.24916058118660614, 0.94873433254679052, 0.93391902477722533, 0.94292907118891411, 0.33489995570586562, 0.16315638867721657, 0.36924866911159543, 0.13739485362291923, 0.90811267309301591, 0.97429962998537578, 0.95705200801005286, 0.18509500616941146, 0.32391626079647007, 0.1388212546270586, 0.34705313656764653, 0.97605863089935385, 0.55633234316128855, 0.15172700268035144, 0.27816617158064427, 0.96568091204770923, 0.80386926588748608, 0.19606567460670393, 0.51328411703221377, 0.18952028936574047, 0.29217711277218322, 0.98495186897421749, 0.75371541481462434, 0.25123847160487478, 0.91740042768853358, 0.99543020205777399, 0.040314380049593479, 0.2418862802975609, 0.72565884089268262, 0.98445895737562161, 0.92102571032336156, 0.98163906061714123, 0.97799317453567647, 0.97990728753832146, 0.24106711290733213, 0.58257885619271932, 0.14062248252927706, 0.040177852151222021, 0.68804314758154173, 0.28970237792907022, 0.97430428626010246, 0.996728438573943, 0.97546436701737105, 0.30810986468344803, 0.68468858818544009, 0.93079447713426255, 0.29847201424008146, 0.69643469989352336, 0.34380523230553134, 0.63030959256014074, 0.36708962487433833, 0.62929649978458002, 0.23400110170696672, 0.74880352546229356, 0.96313585763947207, 0.99580675852952139, 0.82417866815444352, 0.15849589772200837, 0.9367520200957673, 0.15953996193727804, 0.7976998096863902, 0.91776874971685363, 0.79106292911222986, 0.19776573227805747, 0.98827660411470741, 0.29172871642425691, 0.58345743284851381, 0.13614006766465322, 0.99212302126858853, 0.93891035589224081, 0.91904160157238879, 0.2162482804765154, 0.72082760158838466, 0.95251608956158995, 0.96983533538301114, 0.99039043318501252, 0.94942127354940076, 0.97523041873035354, 0.95238068659899622, 0.92615744609973227, 0.9807050864648813, 0.42035125610442675, 0.23229937837349901, 0.3429181299799271, 0.90148676642414294, 0.95493253921552157, 0.9462675520757543, 0.29780054646617182, 0.71472131151881235, 0.90515364762044848, 0.26575125784972026, 0.45902489992224405, 0.26575125784972026, 0.93184033740456096, 0.90607225825285431, 0.97894705284238037, 0.48128159731556169, 0.31387930259710545, 0.20925286839807031, 0.98937067576523985, 0.95002148670479847, 0.18111888581878585, 0.53581003721390819, 0.098106063151842338, 0.18111888581878585, 0.25691687501603078, 0.5386966734207097, 0.2071910282387345, 0.015288183056519005, 0.65739187143031719, 0.32105184418689914, 0.93166519820746685, 0.99340648124319653, 0.97173638258169703, 0.98644810495672253, 0.88756739324224232, 0.96135762527938373, 0.2776532328743771, 0.1287667166953633, 0.5915221048193251, 0.96074587116067556, 0.20338148384176361, 0.79657747838024084, 0.32779417125316823, 0.65558834250633646, 0.9525873931203831, 0.64184897252803885, 0.18686742238158094, 0.1706180813049217, 0.32143332925641305, 0.37631219034897134, 0.17247642057661186, 0.13327723408192735, 0.95256294788169948, 0.3388794462080475, 0.18355970002935906, 0.36711940005871813, 0.1129598154026825, 0.95986504407247797, 0.99357456361333973, 0.93024558128981005], \"Term\": [\"acceptable\", \"acceptable\", \"adjective\", \"alternatives\", \"american\", \"another\", \"another\", \"answer\", \"antonym\", \"apostrophe\", \"appropriate\", \"around\", \"article\", \"based\", \"beginning\", \"book\", \"business\", \"call\", \"call\", \"call\", \"came\", \"change\", \"choose\", \"come\", \"comma\", \"common\", \"common\", \"common\", \"compound\", \"connotation\", \"context\", \"correct\", \"correct\", \"correct\", \"correct\", \"correctly\", \"describe\", \"difference\", \"difference\", \"differences\", \"differences\", \"differences\", \"different\", \"done\", \"done\", \"easy\", \"either\", \"end\", \"ending\", \"english\", \"english\", \"etymology\", \"etymology\", \"ever\", \"every\", \"exactly\", \"example\", \"explain\", \"expression\", \"feel\", \"first\", \"form\", \"form\", \"found\", \"free\", \"friends\", \"full\", \"future\", \"get\", \"go\", \"go\", \"god\", \"god\", \"going\", \"good\", \"got\", \"grammatical\", \"grammatical\", \"hand\", \"hell\", \"help\", \"help\", \"home\", \"internet\", \"kind\", \"know\", \"language\", \"like\", \"like\", \"line\", \"little\", \"long\", \"lost\", \"love\", \"many\", \"mark\", \"may\", \"mean\", \"mean\", \"mean\", \"meaning\", \"meaning\", \"meaning\", \"means\", \"much\", \"multiple\", \"name\", \"name\", \"names\", \"names\", \"negative\", \"non\", \"noun\", \"noun\", \"noun\", \"object\", \"objects\", \"often\", \"one\", \"one\", \"one\", \"one\", \"open\", \"opposite\", \"order\", \"origin\", \"origin\", \"origin\", \"origin\", \"past\", \"people\", \"people\", \"people\", \"perfect\", \"person\", \"person\", \"phrase\", \"phrase\", \"phrase\", \"phrases\", \"plural\", \"plural\", \"positive\", \"possessive\", \"preposition\", \"preposition\", \"preposition\", \"present\", \"pronoun\", \"pronounce\", \"pronounced\", \"pronunciation\", \"proper\", \"proper\", \"proper\", \"proper\", \"punctuation\", \"punctuation\", \"put\", \"question\", \"real\", \"refer\", \"refer\", \"regards\", \"right\", \"right\", \"rules\", \"rules\", \"say\", \"say\", \"saying\", \"saying\", \"see\", \"sentence\", \"sentences\", \"sentences\", \"shall\", \"short\", \"short\", \"show\", \"singular\", \"singular\", \"somebody\", \"someone\", \"someone\", \"someone\", \"something\", \"sometimes\", \"sounds\", \"speak\", \"speak\", \"specific\", \"state\", \"still\", \"story\", \"suffix\", \"synonym\", \"synonyms\", \"tense\", \"term\", \"term\", \"term\", \"text\", \"th\", \"thanks\", \"thing\", \"thing\", \"third\", \"time\", \"time\", \"time\", \"title\", \"true\", \"turn\", \"two\", \"two\", \"two\", \"understand\", \"us\", \"usage\", \"usage\", \"usage\", \"usage\", \"used\", \"used\", \"used\", \"using\", \"using\", \"using\", \"valid\", \"verb\", \"version\", \"versus\", \"vice\", \"voice\", \"vs\", \"vs\", \"vs\", \"want\", \"way\", \"way\", \"without\", \"without\", \"woman\", \"word\", \"word\", \"word\", \"words\", \"words\", \"words\", \"words\", \"world\", \"would\", \"would\", \"would\", \"would\", \"write\", \"year\", \"yet\"]}, \"mdsDat\": {\"y\": [0.022407536095390864, 0.11113551004873343, -0.19298559543860866, 0.059442549294484497], \"cluster\": [1, 1, 1, 1], \"Freq\": [28.854880740038247, 25.740044636171117, 23.392901203473258, 22.012173420317378], \"topics\": [1, 2, 3, 4], \"x\": [0.059413225338190767, -0.18064965739202116, -0.045710771461856613, 0.16694720351568709]}, \"R\": 30, \"lambda.step\": 0.01, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Term\": [\"sentence\", \"difference\", \"english\", \"vs\", \"word\", \"mean\", \"versus\", \"something\", \"verb\", \"say\", \"question\", \"come\", \"meaning\", \"pronunciation\", \"good\", \"different\", \"like\", \"name\", \"way\", \"past\", \"person\", \"end\", \"plural\", \"tense\", \"get\", \"describe\", \"using\", \"correct\", \"first\", \"used\", \"come\", \"good\", \"american\", \"means\", \"expression\", \"many\", \"language\", \"year\", \"synonym\", \"much\", \"non\", \"phrases\", \"context\", \"often\", \"long\", \"going\", \"thanks\", \"valid\", \"synonyms\", \"little\", \"real\", \"kind\", \"found\", \"around\", \"exactly\", \"order\", \"sounds\", \"every\", \"turn\", \"version\", \"english\", \"word\", \"like\", \"plural\", \"sentences\", \"singular\", \"phrase\", \"grammatical\", \"mean\", \"difference\", \"vs\", \"term\", \"say\", \"one\", \"words\", \"meaning\", \"used\", \"people\", \"correct\", \"would\", \"common\", \"usage\", \"sentence\", \"verb\", \"question\", \"pronunciation\", \"different\", \"past\", \"end\", \"tense\", \"know\", \"present\", \"comma\", \"may\", \"article\", \"beginning\", \"perfect\", \"somebody\", \"ever\", \"mark\", \"ending\", \"answer\", \"future\", \"put\", \"suffix\", \"specific\", \"want\", \"still\", \"book\", \"state\", \"correctly\", \"shall\", \"true\", \"correct\", \"using\", \"usage\", \"used\", \"acceptable\", \"go\", \"meaning\", \"proper\", \"words\", \"punctuation\", \"word\", \"origin\", \"english\", \"two\", \"noun\", \"vs\", \"name\", \"time\", \"versus\", \"something\", \"get\", \"describe\", \"pronounce\", \"adjective\", \"appropriate\", \"opposite\", \"possessive\", \"object\", \"us\", \"understand\", \"see\", \"change\", \"apostrophe\", \"got\", \"multiple\", \"full\", \"internet\", \"either\", \"voice\", \"woman\", \"world\", \"home\", \"text\", \"feel\", \"antonym\", \"vice\", \"lost\", \"show\", \"third\", \"person\", \"help\", \"form\", \"names\", \"mean\", \"meaning\", \"right\", \"someone\", \"refer\", \"one\", \"word\", \"would\", \"without\", \"correct\", \"using\", \"used\", \"like\", \"phrase\", \"term\", \"words\", \"first\", \"write\", \"example\", \"love\", \"pronounced\", \"pronoun\", \"line\", \"negative\", \"compound\", \"hand\", \"positive\", \"yet\", \"sometimes\", \"story\", \"choose\", \"open\", \"easy\", \"free\", \"title\", \"connotation\", \"based\", \"th\", \"hell\", \"alternatives\", \"business\", \"came\", \"explain\", \"friends\", \"regards\", \"objects\", \"way\", \"difference\", \"vs\", \"say\", \"call\", \"name\", \"preposition\", \"saying\", \"done\", \"etymology\", \"god\", \"short\", \"another\", \"origin\", \"term\", \"phrase\", \"thing\", \"mean\", \"usage\", \"speak\", \"differences\", \"correct\", \"rules\", \"words\", \"one\", \"people\"], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2334000000000001, 1.2319, 1.2248000000000001, 1.2241, 1.2202, 1.2179, 1.2177, 1.216, 1.2158, 1.2150000000000001, 1.2114, 1.2114, 1.2111000000000001, 1.2096, 1.2050000000000001, 1.2042999999999999, 1.2023999999999999, 1.202, 1.2000999999999999, 1.1984999999999999, 1.1972, 1.1967000000000001, 1.1964999999999999, 1.1961999999999999, 1.1951000000000001, 1.1946000000000001, 1.1922999999999999, 1.1916, 1.1884999999999999, 1.1881999999999999, 1.0455000000000001, 0.80030000000000001, 0.94599999999999995, 0.95550000000000002, 1.0428999999999999, 0.999, 0.58189999999999997, 1.0172000000000001, 0.18740000000000001, 0.19989999999999999, -0.042799999999999998, 0.37080000000000002, 0.24310000000000001, 0.15970000000000001, 0.1101, -0.28439999999999999, -0.12720000000000001, 0.65739999999999998, -0.65949999999999998, 0.15920000000000001, 0.60389999999999999, -0.44879999999999998, 1.3534999999999999, 1.3487, 1.3472999999999999, 1.3451, 1.3447, 1.3426, 1.3407, 1.3404, 1.3372999999999999, 1.3358000000000001, 1.3355999999999999, 1.3312999999999999, 1.3275999999999999, 1.3254999999999999, 1.3248, 1.3239000000000001, 1.3237000000000001, 1.3205, 1.3189, 1.3177000000000001, 1.3147, 1.3110999999999999, 1.3109, 1.3078000000000001, 1.3071999999999999, 1.3053999999999999, 1.3031999999999999, 1.3030999999999999, 1.3010999999999999, 1.3004, 1.3, 0.76700000000000002, 0.94479999999999997, 0.73280000000000001, 0.73699999999999999, 1.0948, 1.0489999999999999, 0.35610000000000003, 0.81020000000000003, 0.38500000000000001, 0.99570000000000003, -0.32129999999999997, 0.2341, -0.37290000000000001, 0.60950000000000004, 0.72499999999999998, -0.68520000000000003, 0.28029999999999999, 0.59760000000000002, 1.4449000000000001, 1.4438, 1.4340999999999999, 1.4332, 1.4323999999999999, 1.4322999999999999, 1.4298, 1.4237, 1.423, 1.421, 1.421, 1.4171, 1.4160999999999999, 1.4126000000000001, 1.4073, 1.4014, 1.4000999999999999, 1.3980999999999999, 1.3975, 1.3967000000000001, 1.3946000000000001, 1.3937999999999999, 1.3934, 1.393, 1.3917999999999999, 1.3885000000000001, 1.3857999999999999, 1.3844000000000001, 1.3838999999999999, 1.3829, 1.3818999999999999, 1.2363999999999999, 1.2658, 1.1642999999999999, 1.2053, 0.78939999999999999, 0.57179999999999997, 1.0781000000000001, 0.90210000000000001, 1.0670999999999999, 0.44929999999999998, -0.31680000000000003, 0.46350000000000002, 1.0506, -0.21629999999999999, 0.29409999999999997, -0.12529999999999999, 0.071800000000000003, -0.19639999999999999, 0.014500000000000001, -0.31979999999999997, 1.4927999999999999, 1.4892000000000001, 1.4841, 1.4831000000000001, 1.4806999999999999, 1.4668000000000001, 1.4655, 1.4601999999999999, 1.4518, 1.45, 1.4496, 1.4488000000000001, 1.4483999999999999, 1.4477, 1.4470000000000001, 1.444, 1.4419, 1.4415, 1.4401999999999999, 1.4397, 1.4387000000000001, 1.4373, 1.4354, 1.4321999999999999, 1.4319, 1.4316, 1.4305000000000001, 1.4302999999999999, 1.4299999999999999, 1.4293, 1.2785, 1.0764, 0.99099999999999999, 1.0490999999999999, 1.1961999999999999, 1.0882000000000001, 1.2090000000000001, 1.2382, 1.2366999999999999, 1.0491999999999999, 1.2605999999999999, 1.3076000000000001, 0.96989999999999998, 0.46450000000000002, 0.44180000000000003, 0.27489999999999998, 1.1540999999999999, -0.48080000000000001, -0.20050000000000001, 1.2110000000000001, 0.95679999999999998, -0.71099999999999997, 1.0334000000000001, -0.52900000000000003, -0.49669999999999997, 0.2442], \"Freq\": [163.0, 234.0, 210.0, 248.0, 369.0, 270.0, 76.0, 66.0, 71.0, 114.0, 61.0, 63.0, 214.0, 50.0, 54.0, 48.0, 88.0, 70.0, 59.0, 40.0, 51.0, 36.0, 67.0, 35.0, 32.0, 31.0, 65.0, 206.0, 29.0, 120.0, 62.425734352305774, 54.089429704264624, 32.480895792502004, 31.607487510593661, 25.932968589421222, 23.528784413255178, 23.062389654551062, 21.554116771311786, 21.46001781190159, 21.282488381700766, 18.730566292265316, 18.692139216126925, 18.422381569293027, 17.438193443674805, 15.329399244402062, 15.070511944363545, 14.207845012590839, 14.42538531091337, 13.448527246524332, 13.011401431535541, 12.732009549678249, 12.674602378931983, 12.856625157752044, 12.409227377632053, 12.734463921506528, 11.947658020902814, 11.378512718692495, 11.190925035815056, 10.64188979089128, 10.717932340541857, 172.908706060138, 237.20316841771489, 65.428994186955336, 50.762340210357337, 25.828854458228925, 31.698031640153065, 65.389968740965998, 19.442419089951645, 94.264861891846763, 82.761847884285729, 68.704700895471007, 37.792554516519424, 42.098599247910954, 39.421477981107131, 41.088562106590302, 46.508967029958363, 30.657725832866078, 22.018675843512185, 30.805519973741688, 23.962021664381911, 21.256412619479889, 24.410108202430628, 163.08642751753857, 70.872873420877866, 60.60085771773187, 49.409507558060227, 47.753108570458011, 40.390006551747327, 35.846439277181197, 35.098417629747175, 29.938708351118049, 27.841910109227388, 27.348159711928403, 23.221383626581222, 19.830853774471645, 18.459359215523229, 18.04613024353467, 17.617497244237015, 17.869135590762237, 15.84592324613668, 15.253368975176306, 14.841299251560251, 13.720562704019089, 12.742982349079142, 12.728165060264264, 11.992348259967535, 11.882375985081348, 11.505403657134082, 10.986620043736398, 10.745576745648272, 10.40679453973925, 10.08615776435829, 10.423628847723863, 114.42388245445365, 43.309373886615816, 70.972581838791342, 64.903336687670418, 20.051456561581141, 20.696620729208913, 78.72208786258021, 28.807598731401569, 48.250558495158451, 19.238154157406704, 68.923305859739116, 28.118270602316795, 37.344319577286882, 22.628793161126353, 21.329930600473666, 32.238008659811761, 24.038292509216625, 19.367583945113264, 75.436340430097161, 65.930801832043471, 32.246689264459818, 30.854231661645176, 28.94766346191776, 28.711645262350604, 25.479665378086768, 19.939350651799028, 19.502201142562097, 18.380437731098713, 18.354507332972993, 16.581137309794329, 16.014618754412133, 14.493672508206544, 12.919652081899629, 11.548908765563709, 11.137076179567631, 10.566873404560999, 10.329749017602019, 10.219031906402654, 9.8146209037853147, 9.8964559764710689, 9.8929044776423485, 9.5568602674329206, 9.3932142322691643, 8.909281366007022, 8.4660605769000323, 8.4182631145477522, 8.3361770698056379, 8.129194483349039, 8.2341945904851386, 41.083008632944072, 18.04502140358084, 30.57970519213092, 22.130267439708707, 139.51918757990995, 88.764766514559923, 20.732390744933959, 29.645899079503671, 19.863342182130967, 42.69261734779942, 62.923011938367232, 26.334859435882795, 14.284496590743023, 38.901653959341367, 20.533784015445722, 24.902140654115922, 22.130915690438382, 24.341696453393787, 21.455135965948795, 21.672074364699196, 28.814315814288303, 24.402304877106626, 20.184389776572115, 19.39970496538983, 17.809240923384777, 12.434006835682769, 12.22732824438406, 11.068353355340365, 9.3937689096529056, 8.9827759023240006, 9.2020353400050929, 9.0680910211872163, 8.9807287860203697, 8.875087288233761, 8.9565417314876523, 8.2171629052659085, 8.2996189410300527, 7.9992948316511061, 7.9774029181148558, 7.7923331928520998, 7.6977369731801586, 7.7624109522803799, 7.3586295028747788, 7.2106125057337787, 7.0400670859421837, 7.0147637068781075, 7.0189686194096517, 6.896328987165413, 6.9178109015046454, 6.8895015396177612, 46.641732897454268, 151.68896538010716, 147.36508425692043, 71.907388588000586, 27.417959218266574, 46.112055014172192, 18.291308286046831, 16.223562291315623, 16.191496426449451, 26.664084837395244, 11.584063398864991, 10.202384494758714, 16.019469332283482, 30.278726510426051, 30.952678260734622, 36.696646478178344, 11.720109513511035, 36.863017783308827, 23.868396216060017, 10.250445848182213, 11.4066437380124, 22.320265691785799, 10.796550604544116, 16.542472523003877, 15.598662823507505, 11.112098127738138], \"Total\": [163.0, 234.0, 210.0, 248.0, 369.0, 270.0, 76.0, 66.0, 71.0, 114.0, 61.0, 63.0, 214.0, 50.0, 54.0, 48.0, 88.0, 70.0, 59.0, 40.0, 51.0, 36.0, 67.0, 35.0, 32.0, 31.0, 65.0, 206.0, 29.0, 120.0, 63.024147751350135, 54.684717838048812, 33.075334301875372, 32.207330524433132, 26.527967161936726, 24.123213714783205, 23.650415387131609, 22.142273771575272, 22.050006153518456, 21.883924421988105, 19.329145072398923, 19.290282701618338, 19.017666753068855, 18.028927646238706, 15.920891105554601, 15.662866678564967, 14.794969952514252, 15.026857316272134, 14.036490290874484, 13.602651949028939, 13.326986038197843, 13.273488927931057, 13.466862651438298, 13.00270009910348, 13.357312887619111, 12.538503550032729, 11.968990284204866, 11.780162492431552, 11.236562762062988, 11.319942524715744, 210.65056470240492, 369.24574182386306, 88.047272156039284, 67.664796284607505, 31.546557809147082, 40.451901893458704, 126.6355179190565, 24.364267005979197, 270.84796627254633, 234.85256716160697, 248.51142299221391, 90.400586291003634, 114.41347603974748, 116.45268784165722, 127.55366748945184, 214.19928827539363, 120.66159530418429, 39.544707889869869, 206.45132207932249, 70.821645480575214, 40.271831343871561, 132.5096490711224, 163.68637650210098, 71.471247007717523, 61.200220279934022, 50.00473067518007, 48.352405954287498, 40.981144711710044, 36.441752839507245, 35.688608617462634, 30.537539741258687, 28.442018623755143, 27.943477394871021, 23.829069815997347, 20.425099274614666, 19.053080058997494, 18.639697414989097, 18.21352435649764, 18.477103831274427, 16.436400862194162, 15.847522489062236, 15.43834577772223, 14.315538375109696, 13.342854160994106, 13.3301830524571, 12.598212388751547, 12.490295675694988, 12.116433678997693, 11.595554082287789, 11.342131595623743, 11.006551077327668, 10.675183811162389, 11.036647363293774, 206.45132207932249, 65.409996485723127, 132.5096490711224, 120.66159530418429, 26.067073488836051, 28.164407231978036, 214.19928827539363, 49.778668916207096, 127.55366748945184, 27.614547237022315, 369.24574182386306, 86.442094420179643, 210.65056470240492, 47.789070116719216, 40.134759488743555, 248.51142299221391, 70.561074083766755, 41.392090065742579, 76.030355396435581, 66.524008197701534, 32.852598148264789, 31.462495714873217, 29.542426705970879, 29.303232537514575, 26.071761004375375, 20.527566042799585, 20.091815537297929, 18.972645325989888, 18.946939887048224, 17.182639850176638, 16.612401950451765, 15.087848661431444, 13.520074924938521, 12.156866961519299, 11.738722151173855, 11.160075412043646, 10.916410102598412, 10.8075020176764, 10.401956292897623, 10.497724484094922, 10.497993882963751, 10.145476979793751, 9.9835076178650919, 9.5005901422613679, 9.0520739439509175, 9.0134000650659019, 8.9301930900417705, 8.7167927677512758, 8.8382784746337144, 51.00331825068006, 21.754699181042128, 40.805662469585194, 28.342637075811371, 270.84796627254633, 214.19928827539363, 30.153580806945218, 51.417632737209573, 29.210359782691789, 116.45268784165722, 369.24574182386306, 70.821645480575214, 21.3548641613692, 206.45132207932249, 65.409996485723127, 120.66159530418429, 88.047272156039284, 126.6355179190565, 90.400586291003634, 127.55366748945184, 29.41833130112564, 25.003514971410706, 20.788392086345702, 20.000018662383706, 18.405036424253055, 13.028952249103815, 12.829562014519643, 11.675692669691921, 9.9928395483006245, 9.5726484364513702, 9.8103289778011611, 9.6748645529939115, 9.5855796493450693, 9.4794589617247578, 9.5732122547193157, 8.8094795249934563, 8.9161403246018285, 8.5975037479104586, 8.5851617266132347, 8.389617239672619, 8.2960775822703088, 8.3775551376351789, 7.9570579218549504, 7.8218324083172934, 7.6389916319705096, 7.613887893334903, 7.6266012609837048, 7.4953479741606843, 7.520457170686762, 7.4952965024668625, 59.002421328267673, 234.85256716160697, 248.51142299221391, 114.41347603974748, 37.659352955883563, 70.561074083766755, 24.805044720266849, 21.367420766511454, 21.355545463714741, 42.424389059161697, 14.91853437815476, 12.536044109038244, 27.591091005697262, 86.442094420179643, 90.400586291003634, 126.6355179190565, 16.789760997191344, 270.84796627254633, 132.5096490711224, 13.872942681390711, 19.904149755141219, 206.45132207932249, 17.451741382073983, 127.55366748945184, 116.45268784165722, 39.544707889869869], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.5945, -4.7378, -5.2477999999999998, -5.2750000000000004, -5.4729000000000001, -5.5701999999999998, -5.5902000000000003, -5.6578999999999997, -5.6623000000000001, -5.6706000000000003, -5.7983000000000002, -5.8003, -5.8148999999999997, -5.8697999999999997, -5.9987000000000004, -6.0156999999999998, -6.0746000000000002, -6.0594999999999999, -6.1295999999999999, -6.1626000000000003, -6.1843000000000004, -6.1887999999999996, -6.1745999999999999, -6.21, -6.1840999999999999, -6.2478999999999996, -6.2967000000000004, -6.3132999999999999, -6.3635999999999999, -6.3564999999999996, -3.5756999999999999, -3.2595000000000001, -4.5475000000000003, -4.8013000000000003, -5.4768999999999997, -5.2721999999999998, -4.5480999999999998, -5.7610000000000001, -4.1822999999999997, -4.3125, -4.4985999999999997, -5.0963000000000003, -4.9884000000000004, -5.0541, -5.0126999999999997, -4.8887999999999998, -5.3056000000000001, -5.6365999999999996, -5.3007, -5.5519999999999996, -5.6718000000000002, -5.5334000000000003, -3.5198999999999998, -4.3532999999999999, -4.5099, -4.7141000000000002, -4.7481999999999998, -4.9156000000000004, -5.0350000000000001, -5.0560999999999998, -5.2150999999999996, -5.2877000000000001, -5.3056000000000001, -5.4691000000000001, -5.6269999999999998, -5.6985999999999999, -5.7213000000000003, -5.7453000000000003, -5.7310999999999996, -5.8513000000000002, -5.8894000000000002, -5.9168000000000003, -5.9953000000000003, -6.0692000000000004, -6.0704000000000002, -6.1299000000000001, -6.1391999999999998, -6.1714000000000002, -6.2175000000000002, -6.2397, -6.2717999999999998, -6.3029999999999999, -6.2701000000000002, -3.8742999999999999, -4.8457999999999997, -4.3518999999999997, -4.4413, -5.6158999999999999, -5.5842000000000001, -4.2483000000000004, -5.2535999999999996, -4.7378, -5.6573000000000002, -4.3811999999999998, -5.2778, -4.9939999999999998, -5.4950000000000001, -5.5541, -5.1410999999999998, -5.4345999999999997, -5.6505999999999998, -4.1952999999999996, -4.3300000000000001, -5.0452000000000004, -5.0892999999999997, -5.1531000000000002, -5.1612999999999998, -5.2807000000000004, -5.5259, -5.5480999999999998, -5.6073000000000004, -5.6086999999999998, -5.7103000000000002, -5.7450999999999999, -5.8449, -5.9598000000000004, -6.0720000000000001, -6.1082999999999998, -6.1608999999999998, -6.1836000000000002, -6.1943000000000001, -6.2347000000000001, -6.2263999999999999, -6.2267999999999999, -6.2613000000000003, -6.2786, -6.3315000000000001, -6.3825000000000003, -6.3882000000000003, -6.3979999999999997, -6.4230999999999998, -6.4103000000000003, -4.8029999999999999, -5.6257000000000001, -5.0983000000000001, -5.4215999999999998, -3.5804, -4.0326000000000004, -5.4869000000000003, -5.1292999999999997, -5.5297000000000001, -4.7645999999999997, -4.3766999999999996, -5.2477, -5.8593999999999999, -4.8575999999999997, -5.4965000000000002, -5.3036000000000003, -5.4215999999999998, -5.3263999999999996, -5.4526000000000003, -5.4425999999999997, -5.0968999999999998, -5.2630999999999997, -5.4527999999999999, -5.4924999999999997, -5.5780000000000003, -5.9372999999999996, -5.9541000000000004, -6.0537000000000001, -6.2176999999999998, -6.2624000000000004, -6.2382999999999997, -6.2530000000000001, -6.2626999999999997, -6.2744999999999997, -6.2653999999999996, -6.3514999999999997, -6.3414999999999999, -6.3784000000000001, -6.3811, -6.4046000000000003, -6.4168000000000003, -6.4085000000000001, -6.4619, -6.4821999999999997, -6.5061, -6.5096999999999996, -6.5091000000000001, -6.5267999999999997, -6.5236999999999998, -6.5278, -4.6153000000000004, -3.4359000000000002, -3.4647999999999999, -4.1824000000000003, -5.1466000000000003, -4.6266999999999996, -5.5513000000000003, -5.6712999999999996, -5.6733000000000002, -5.1744000000000003, -6.0080999999999998, -6.1351000000000004, -5.6840000000000002, -5.0472999999999999, -5.0252999999999997, -4.8551000000000002, -5.9965000000000002, -4.8505000000000003, -5.2851999999999997, -6.1303999999999998, -6.0236000000000001, -5.3522999999999996, -6.0785, -5.6517999999999997, -5.7106000000000003, -6.0496999999999996]}};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el223221396349203060009717630586\", ldavis_el223221396349203060009717630586_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el223221396349203060009717630586\", ldavis_el223221396349203060009717630586_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el223221396349203060009717630586\", ldavis_el223221396349203060009717630586_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "3      28.854881        1       1  0.059413  0.022408\n",
       "0      25.740045        1       2 -0.180650  0.111136\n",
       "2      23.392901        1       3 -0.045711 -0.192986\n",
       "1      22.012173        1       4  0.166947  0.059443, topic_info=     Category        Freq           Term       Total  loglift  logprob\n",
       "term                                                                  \n",
       "3304  Default  163.000000       sentence  163.000000  30.0000  30.0000\n",
       "3831  Default  234.000000     difference  234.000000  29.0000  29.0000\n",
       "5932  Default  210.000000        english  210.000000  28.0000  28.0000\n",
       "1418  Default  248.000000             vs  248.000000  27.0000  27.0000\n",
       "1585  Default  369.000000           word  369.000000  26.0000  26.0000\n",
       "3135  Default  270.000000           mean  270.000000  25.0000  25.0000\n",
       "1626  Default   76.000000         versus   76.000000  24.0000  24.0000\n",
       "5739  Default   66.000000      something   66.000000  23.0000  23.0000\n",
       "2286  Default   71.000000           verb   71.000000  22.0000  22.0000\n",
       "3268  Default  114.000000            say  114.000000  21.0000  21.0000\n",
       "5646  Default   61.000000       question   61.000000  20.0000  20.0000\n",
       "5147  Default   63.000000           come   63.000000  19.0000  19.0000\n",
       "5673  Default  214.000000        meaning  214.000000  18.0000  18.0000\n",
       "4140  Default   50.000000  pronunciation   50.000000  17.0000  17.0000\n",
       "5193  Default   54.000000           good   54.000000  16.0000  16.0000\n",
       "3896  Default   48.000000      different   48.000000  15.0000  15.0000\n",
       "4455  Default   88.000000           like   88.000000  14.0000  14.0000\n",
       "5027  Default   70.000000           name   70.000000  13.0000  13.0000\n",
       "1851  Default   59.000000            way   59.000000  12.0000  12.0000\n",
       "772   Default   40.000000           past   40.000000  11.0000  11.0000\n",
       "163   Default   51.000000         person   51.000000  10.0000  10.0000\n",
       "4596  Default   36.000000            end   36.000000   9.0000   9.0000\n",
       "5793  Default   67.000000         plural   67.000000   8.0000   8.0000\n",
       "4397  Default   35.000000          tense   35.000000   7.0000   7.0000\n",
       "3645  Default   32.000000            get   32.000000   6.0000   6.0000\n",
       "2251  Default   31.000000       describe   31.000000   5.0000   5.0000\n",
       "2191  Default   65.000000          using   65.000000   4.0000   4.0000\n",
       "3557  Default  206.000000        correct  206.000000   3.0000   3.0000\n",
       "3574  Default   29.000000          first   29.000000   2.0000   2.0000\n",
       "2557  Default  120.000000           used  120.000000   1.0000   1.0000\n",
       "...       ...         ...            ...         ...      ...      ...\n",
       "3210   Topic4    7.018969        explain    7.626601   1.4305  -6.5091\n",
       "3007   Topic4    6.896329        friends    7.495348   1.4303  -6.5268\n",
       "5818   Topic4    6.917811        regards    7.520457   1.4300  -6.5237\n",
       "4194   Topic4    6.889502        objects    7.495297   1.4293  -6.5278\n",
       "1851   Topic4   46.641733            way   59.002421   1.2785  -4.6153\n",
       "3831   Topic4  151.688965     difference  234.852567   1.0764  -3.4359\n",
       "1418   Topic4  147.365084             vs  248.511423   0.9910  -3.4648\n",
       "3268   Topic4   71.907389            say  114.413476   1.0491  -4.1824\n",
       "3076   Topic4   27.417959           call   37.659353   1.1962  -5.1466\n",
       "5027   Topic4   46.112055           name   70.561074   1.0882  -4.6267\n",
       "5965   Topic4   18.291308    preposition   24.805045   1.2090  -5.5513\n",
       "180    Topic4   16.223562         saying   21.367421   1.2382  -5.6713\n",
       "3947   Topic4   16.191496           done   21.355545   1.2367  -5.6733\n",
       "1534   Topic4   26.664085      etymology   42.424389   1.0492  -5.1744\n",
       "4635   Topic4   11.584063            god   14.918534   1.2606  -6.0081\n",
       "5414   Topic4   10.202384          short   12.536044   1.3076  -6.1351\n",
       "1671   Topic4   16.019469        another   27.591091   0.9699  -5.6840\n",
       "5053   Topic4   30.278727         origin   86.442094   0.4645  -5.0473\n",
       "5025   Topic4   30.952678           term   90.400586   0.4418  -5.0253\n",
       "2346   Topic4   36.696646         phrase  126.635518   0.2749  -4.8551\n",
       "3569   Topic4   11.720110          thing   16.789761   1.1541  -5.9965\n",
       "3135   Topic4   36.863018           mean  270.847966  -0.4808  -4.8505\n",
       "5946   Topic4   23.868396          usage  132.509649  -0.2005  -5.2852\n",
       "1764   Topic4   10.250446          speak   13.872943   1.2110  -6.1304\n",
       "4861   Topic4   11.406644    differences   19.904150   0.9568  -6.0236\n",
       "3557   Topic4   22.320266        correct  206.451322  -0.7110  -5.3523\n",
       "1032   Topic4   10.796551          rules   17.451741   1.0334  -6.0785\n",
       "5853   Topic4   16.542473          words  127.553667  -0.5290  -5.6518\n",
       "532    Topic4   15.598663            one  116.452688  -0.4967  -5.7106\n",
       "303    Topic4   11.112098         people   39.544708   0.2442  -6.0497\n",
       "\n",
       "[238 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "3472      2  0.767251    acceptable\n",
       "3472      3  0.230175    acceptable\n",
       "4907      3  0.989652     adjective\n",
       "4905      4  0.894931  alternatives\n",
       "2414      1  0.967488      american\n",
       "1671      1  0.398679       another\n",
       "1671      4  0.579897       another\n",
       "3102      2  0.971607        answer\n",
       "82        3  0.883775       antonym\n",
       "2165      3  0.961533    apostrophe\n",
       "1089      3  0.958892   appropriate\n",
       "670       1  0.922885        around\n",
       "2130      2  0.979187       article\n",
       "2834      4  0.964311         based\n",
       "3942      2  0.944729     beginning\n",
       "6017      2  0.948639          book\n",
       "2210      4  0.916351      business\n",
       "3076      2  0.106215          call\n",
       "3076      3  0.159323          call\n",
       "3076      4  0.716953          call\n",
       "179       4  0.919373          came\n",
       "1923      3  0.927899        change\n",
       "5767      4  0.940123        choose\n",
       "5147      1  0.983750          come\n",
       "1368      2  0.966236         comma\n",
       "4006      1  0.521456        common\n",
       "4006      2  0.273144        common\n",
       "4006      4  0.198650        common\n",
       "3917      4  0.900645      compound\n",
       "5465      4  0.953560   connotation\n",
       "...     ...       ...           ...\n",
       "2261      1  0.931665         valid\n",
       "2286      2  0.993406          verb\n",
       "5366      1  0.971736       version\n",
       "1626      3  0.986448        versus\n",
       "5674      3  0.887567          vice\n",
       "1779      3  0.961358         voice\n",
       "1418      1  0.277653            vs\n",
       "1418      2  0.128767            vs\n",
       "1418      4  0.591522            vs\n",
       "67        2  0.960746          want\n",
       "1851      3  0.203381           way\n",
       "1851      4  0.796577           way\n",
       "5215      2  0.327794       without\n",
       "5215      3  0.655588       without\n",
       "1596      3  0.952587         woman\n",
       "1585      1  0.641849          word\n",
       "1585      2  0.186867          word\n",
       "1585      3  0.170618          word\n",
       "5853      1  0.321433         words\n",
       "5853      2  0.376312         words\n",
       "5853      3  0.172476         words\n",
       "5853      4  0.133277         words\n",
       "675       3  0.952563         world\n",
       "4571      1  0.338879         would\n",
       "4571      2  0.183560         would\n",
       "4571      3  0.367119         would\n",
       "4571      4  0.112960         would\n",
       "1963      4  0.959865         write\n",
       "2021      1  0.993575          year\n",
       "3312      4  0.930246           yet\n",
       "\n",
       "[259 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 3, 2])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(ldamodel,corpus,dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self,df,field,tag):\n",
    "        self.df = df\n",
    "        self.field = field\n",
    "        self.tag = tag\n",
    "\n",
    "    def __iter__(self):\n",
    "        for index, row in self.df.iterrows():\n",
    "            tokens = stop_words.remove(row[self.field])\n",
    "            yield doc2vec.TaggedDocument(words=tokens,tags=[row[self.tag]])\n",
    "\n",
    "lablines = LabeledLineSentence(posts,'Title','Id')\n",
    "# print([p for p in lablines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docmodel = doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025)\n",
    "docmodel.build_vocab(lablines)\n",
    "for epoch in range(10):\n",
    "    docmodel.train(lablines)\n",
    "    docmodel.alpha -= 0.002  # decrease the learning rate\n",
    "    docmodel.min_alpha = docmodel.alpha  # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     90.76% : which is correct   one or more is  or  one or more are  \n",
      "     87.12% : what s the meaning of  get one s finger in the air  \n",
      "     86.85% : what is the difference between  used to  and  i was used to  \n",
      "     86.75% : what s the difference between these sentences \n",
      "     86.13% : what s the difference between these sentences \n",
      "     85.96% : how did  mad  come to be a determiner \n",
      "     85.89% : where does  santa  in santa claus come from \n",
      "     85.86% : where does the  quint  in  quintessential  come from \n",
      "     85.83% : where does  pull it off  come from \n",
      "     85.80% : where does  can t be arsed  come from \n"
     ]
    }
   ],
   "source": [
    "class MatchingPost(object):\n",
    "    matchingPercentage = 0\n",
    "    title = \"\"\n",
    "    \n",
    "    def __init__(self, matchingPercentage, title):\n",
    "        self.matchingPercentage = matchingPercentage\n",
    "        self.title = title\n",
    "        \n",
    "\n",
    "def showsimilar(question):\n",
    "    if (type(question) is not 'str'):\n",
    "        question = str(question)\n",
    "        \n",
    "    norm_input = stop_words.remove(question) # question.split()\n",
    "    q_vector = docmodel.infer_vector(norm_input)\n",
    "    similar_vecs = docmodel.docvecs.most_similar(positive=[q_vector])\n",
    "    similarTitles = []\n",
    "    \n",
    "    for vec in similar_vecs:\n",
    "        post = posts[posts['Id']==vec[0]]\n",
    "        if(len(post) == 0): continue\n",
    "        title = posts[posts['Id']==vec[0]]['Title']\n",
    "        similarPostInfo = MatchingPost(vec[1], title.iloc[0])\n",
    "        similarTitles.append(similarPostInfo)\n",
    "    \n",
    "    # Show top 10 matches only\n",
    "    for title in similarTitles:\n",
    "        post = title.title\n",
    "        matchPercentage = title.matchingPercentage\n",
    "        print(\"{:10.2f}% : {}\".format(matchPercentage * 100, post))\n",
    "\n",
    "    return similarTitles\n",
    "\n",
    "\n",
    "similarTitles = showsimilar(\"Where does the quint in quintessential come from?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     66.27% : what s the meaning of  get one s finger in the air  \n",
      "     59.08% : can  found  be used  as it is in this sentence  in the future tense \n",
      "     58.78% : what does  capacity  mean in this question \n",
      "     54.69% : difference between  get  and  take \n",
      "     52.43% : does anybody pronounce the word  pillow  as  pellow  \n",
      "     50.19% : when does a word become a  word  \n",
      "     49.68% : colons and semi colons\n",
      "     48.07% : how long does it take to mull something over \n",
      "     47.89% : can a book be divided in categories \n",
      "     47.71% : where does the  quint  in  quintessential  come from \n",
      "     55.30% :  prove me     prove to me     confirm one s belief \n",
      "     52.84% : colons and semi colons\n",
      "     52.78% : difference between  get  and  take \n",
      "     49.12% : what s the meaning of  get one s finger in the air  \n",
      "     49.11% :  in the middle of riddle  means what \n",
      "     48.67% : is it wrong to pronounce  pizza  as  peedtza  \n",
      "     48.03% : can you use   sic   in other contexts \n",
      "     47.69% : can we say  had einstein used his spare time on something more useful for the society      \n",
      "     47.35% : what is a catchy word that means  non  self descriptive\n",
      "     45.68% : rules to pronounce  cha   words\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "def handler(sender):\n",
    "    showsimilar(text.value)\n",
    "    \n",
    "text = widgets.Text()    \n",
    "display(text)    \n",
    "text.on_submit(handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## References\n",
    "\n",
    "* https://rstudio-pubs-static.s3.amazonaws.com/79360_850b2a69980c4488b1db95987a24867a.html\n",
    "* LDA Viz - http://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf\n",
    "* This dashboard @ https://github.com/dhruvaray/soml\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
